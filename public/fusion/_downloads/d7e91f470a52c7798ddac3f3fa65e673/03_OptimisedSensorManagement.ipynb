{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# 3 - Optimised Sensor Management\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This tutorial follows on from the Multi Sensor Management tutorial and explores the use of\nexternal optimisation libraries to overcome the limitations of the brute force optimisation\nmethod introduced in the previous tutorial.\n\nThe scenario in this example is the same as Tutorial 2, simulating 3\ntargets moving on nearly constant velocity trajectories and an adjustable number of sensors.\nThe sensors are\n:class:`~.RadarRotatingBearingRange` with a defined field of view which can be pointed in a\nparticular direction in order\nto make an observation.\n\nThe optimised sensor managers are built around the SciPy optimize library. Similar to the brute\nforce method introduced previously the sensor manager considers all possible configurations of\nsensors and actions and here uses an optimising function to optimise over a given reward function,\nreturning the optimal configuration.\n\nThe :class:`~.UncertaintyRewardFunction` is used for all sensor managers which chooses the configuration\nfor which the sum of estimated\nuncertainties (as represented by the Frobenius norm of the covariance matrix) can be reduced the most by using\nthe chosen sensing configuration.\n\nAs in the previous tutorials the SIAP [#]_ and uncertainty metrics are used to assess the\nperformance of the sensor managers.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sensor Management example\n\n### Setup\n\nFirst a simulation must be set up using components from SMART FUSION. For this the following imports are required.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport random\nfrom datetime import datetime, timedelta\n\nstart_time = datetime.now()\n\nfrom smartfusion.models.transition.linear import CombinedLinearGaussianTransitionModel, ConstantVelocity\nfrom smartfusion.types.groundtruth import GroundTruthPath, GroundTruthState"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generate ground truths\n\nGenerate transition model and ground truths as in Tutorials 1 & 2.\n\nThe number of targets in this simulation is defined by `ntruths` - here there are 3 targets travelling in\ndifferent directions. The time the\nsimulation is observed for is defined by `time_max`.\n\nWe can fix our random number generator in order to probe a particular example repeatedly. This can be undone by\ncommenting out the first two lines in the next cell.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "np.random.seed(1990)\nrandom.seed(1990)\n\n# Generate transition model\ntransition_model = CombinedLinearGaussianTransitionModel([ConstantVelocity(0.005),\n                                                          ConstantVelocity(0.005)])\n\nyps = range(0, 100, 10)  # y value for prior state\ntruths = []\nntruths = 3  # number of ground truths in simulation\ntime_max = 50  # timestamps the simulation is observed over\n\nxdirection = 1\nydirection = 1\n\n# Generate ground truths\nfor j in range(0, ntruths):\n    truth = GroundTruthPath([GroundTruthState([0, xdirection, yps[j], ydirection], timestamp=start_time)],\n                            id=f\"id{j}\")\n\n    for k in range(1, time_max):\n        truth.append(\n            GroundTruthState(transition_model.function(truth[k - 1], noise=True, time_interval=timedelta(seconds=1)),\n                             timestamp=start_time + timedelta(seconds=k)))\n    truths.append(truth)\n\n    xdirection *= -1\n    if j % 2 == 0:\n        ydirection *= -1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the ground truths. This is done using the :class:`~.Plotterly` class from SMART FUSION.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.plotter import Plotterly\n\n# Smartfusion plotter requires sets not lists\ntruths_set = set(truths)\n\nplotter = Plotterly()\nplotter.plot_ground_truths(truths_set, [0, 2])\nplotter.fig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create sensors\nCreate a set of sensors for each sensor management algorithm. As in Tutorial 2 this tutorial uses the\n:class:`~.RadarRotatingBearingRange` sensor with the\nnumber of sensors initially set as 2 and each sensor positioned along the line $x=10$, at distance\nintervals of 50.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "total_no_sensors = 2\n\nfrom smartfusion.types.state import StateVector\nfrom smartfusion.sensor.radar.radar import RadarRotatingBearingRange\nfrom smartfusion.types.angle import Angle\n\nsensor_setA = set()\nfor n in range(0, total_no_sensors):\n    sensor = RadarRotatingBearingRange(\n        position_mapping=(0, 2),\n        noise_covar=np.array([[np.radians(0.5) ** 2, 0],\n                              [0, 1 ** 2]]),\n        ndim_state=4,\n        position=np.array([[10], [n * 50]]),\n        rpm=60,\n        fov_angle=np.radians(30),\n        dwell_centre=StateVector([0.0]),\n        max_range=np.inf,\n        resolutions={'dwell_centre': Angle(np.radians(30))}\n    )\n    sensor_setA.add(sensor)\nfor sensor in sensor_setA:\n    sensor.timestamp = start_time\n\nsensor_setB = set()\nfor n in range(0, total_no_sensors):\n    sensor = RadarRotatingBearingRange(\n        position_mapping=(0, 2),\n        noise_covar=np.array([[np.radians(0.5) ** 2, 0],\n                              [0, 1 ** 2]]),\n        ndim_state=4,\n        position=np.array([[10], [n * 50]]),\n        rpm=60,\n        fov_angle=np.radians(30),\n        dwell_centre=StateVector([0.0]),\n        max_range=np.inf,\n        resolutions={'dwell_centre': Angle(np.radians(30))}\n    )\n    sensor_setB.add(sensor)\n\nfor sensor in sensor_setB:\n    sensor.timestamp = start_time\n\nsensor_setC = set()\nfor n in range(0, total_no_sensors):\n    sensor = RadarRotatingBearingRange(\n        position_mapping=(0, 2),\n        noise_covar=np.array([[np.radians(0.5) ** 2, 0],\n                              [0, 1 ** 2]]),\n        ndim_state=4,\n        position=np.array([[10], [n * 50]]),\n        rpm=60,\n        fov_angle=np.radians(30),\n        dwell_centre=StateVector([0.0]),\n        max_range=np.inf,\n        resolutions={'dwell_centre': Angle(np.radians(30))}\n    )\n    sensor_setC.add(sensor)\n\nfor sensor in sensor_setC:\n    sensor.timestamp = start_time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create the Kalman predictor and updater\n\nConstruct a predictor and updater using the :class:`~.KalmanPredictor` and :class:`~.ExtendedKalmanUpdater`\ncomponents from SMART FUSION. The measurement model for the updater is `None` as it is an attribute of the sensor.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.predictor.kalman import KalmanPredictor\npredictor = KalmanPredictor(transition_model)\n\nfrom smartfusion.updater.kalman import ExtendedKalmanUpdater\nupdater = ExtendedKalmanUpdater(measurement_model=None)\n# measurement model is added to detections by the sensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run the Kalman filters\n\nCreate priors which estimate the targets' initial states - these are the same as in the previous\nsensor management tutorials.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.types.state import GaussianState\n\npriors = []\nxdirection = 1.2\nydirection = 1.2\nfor j in range(0, ntruths):\n    priors.append(GaussianState([[0], [xdirection], [yps[j]+0.1], [ydirection]],\n                                np.diag([0.5, 0.5, 0.5, 0.5]+np.random.normal(0,5e-4,4)),\n                                timestamp=start_time))\n    xdirection *= -1\n    if j % 2 == 0:\n        ydirection *= -1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Initialise the tracks by creating an empty list and appending the priors generated. This needs to be done\nseparately for each sensor manager method as they will generate different sets of tracks.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.types.track import Track\n\n# Initialise tracks from the BruteForceSensorManager\ntracksA = []\nfor j, prior in enumerate(priors):\n    tracksA.append(Track([prior]))\n\n# Initialise tracks from the OptimizeBruteSensorManager\ntracksB = []\nfor j, prior in enumerate(priors):\n    tracksB.append(Track([prior]))\n\n# Initialise tracks from the OptimizeBasinHoppingSensorManager\ntracksC = []\nfor j, prior in enumerate(priors):\n    tracksC.append(Track([prior]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create sensor managers\n\nThe :class:`~.UncertaintyRewardFunction` will be used for each sensor manager as in Tutorials 1 & 2\nand the :class:`~.BruteForceSensorManager` will be used as a comparison to the optimised methods.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.sensormanager.reward import UncertaintyRewardFunction\nfrom smartfusion.sensormanager import BruteForceSensorManager"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Optimised Brute Force Sensor Manager\n\nThe first optimised method, :class:`~.OptimizeBruteSensorManager` uses :func:`~.scipy.optimize.brute`\nwhich minimizes a function over a given range using a brute force method. This can be tailored by setting\nthe number of grid points to search over or by adding the use of a polishing function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.sensormanager import OptimizeBruteSensorManager"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Optimised Basin Hopping Sensor Manager\n\nThe second optimised method, :class:`~.OptimizeBasinHoppingSensorManager` uses :func:`~.scipy.optimize.basinhopping`\nwhich finds the global minimum of a function using the basin-hopping algorithm. This is a combination of a\nglobal stepping algorithm and local minimization at each step. Parameters such as number of basin hopping\niterations or stepsize can be set to tailor the algorithm to requirements.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.sensormanager import OptimizeBasinHoppingSensorManager"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initiate sensor managers\n\nCreate an instance of each sensor manager class. For the optimised sensor managers the default settings\nwill be used meaning only a sensor set and reward function is required. The :class:`~.UncertaintyRewardFunction`\nwill be used for each sensor manager. For the :class:`~.OptimizeBruteSensorManager` a polishing function\nis used by setting `finish=True`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# initiate reward function\nreward_function = UncertaintyRewardFunction(predictor, updater)\n\nbruteforcesensormanager = BruteForceSensorManager(sensor_setA,\n                                                  reward_function=reward_function)\n\noptimizebrutesensormanager = OptimizeBruteSensorManager(sensor_setB,\n                                                        reward_function=reward_function,\n                                                        finish=True)\n\noptimizebasinhoppingsensormanager = OptimizeBasinHoppingSensorManager(sensor_setC,\n                                                                      reward_function=reward_function)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run the sensor managers\n\nEach sensor management method requires a timestamp and a list of tracks at each time step when calling\nthe function :meth:`choose_actions`. This returns a mapping of sensors and actions to be taken by each\nsensor, decided by the sensor managers.\n\nFor each sensor management method, at each time step the chosen action is given to the sensors and then\nmeasurements taken. At each timestep the tracks are predicted and those with measurements associated are\nupdated.\n\nFirst a hypothesiser and data associator are required for use in each tracker.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.hypothesiser.distance import DistanceHypothesiser\nfrom smartfusion.measures import Mahalanobis\nhypothesiser = DistanceHypothesiser(predictor, updater, measure=Mahalanobis(), missed_distance=5)\n\nfrom smartfusion.dataassociator.neighbour import GNNWith2DAssignment\ndata_associator = GNNWith2DAssignment(hypothesiser)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Run brute force sensor manager\n\nEach sensor manager is run in the same way as in the previous tutorials.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from ordered_set import OrderedSet\nimport time\n\n# Start timer for cell execution time\ncell_start_time1 = time.time()\n\n# Generate list of timesteps from ground truth timestamps\ntimesteps = []\nfor state in truths[0]:\n    timesteps.append(state.timestamp)\n\nfor timestep in timesteps[1:]:\n\n    # Generate chosen configuration\n    chosen_actions = bruteforcesensormanager.choose_actions(tracksA, timestep)\n\n    # Create empty dictionary for measurements\n    measurementsA = []\n\n    for chosen_action in chosen_actions:\n        for sensor, actions in chosen_action.items():\n            sensor.add_actions(actions)\n\n    for sensor in sensor_setA:\n        sensor.act(timestep)\n\n        # Observe this ground truth\n        measurements = sensor.measure(OrderedSet(truth[timestep] for truth in truths), noise=True)\n        measurementsA.extend(measurements)\n\n    hypotheses = data_associator.associate(tracksA,\n                                           measurementsA,\n                                           timestep)\n    for track in tracksA:\n        hypothesis = hypotheses[track]\n        if hypothesis.measurement:\n            post = updater.update(hypothesis)\n            track.append(post)\n        else:  # When data associator says no detections are good enough, we'll keep the prediction\n            track.append(hypothesis.prediction)\n\ncell_run_time1 = round(time.time() - cell_start_time1, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot ground truths, tracks and uncertainty ellipses for each target. The positions of the sensors are indicated\nby black x markers.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plotterA = Plotterly()\nplotterA.plot_sensors(sensor_setA)\nplotterA.plot_ground_truths(truths_set, [0, 2])\nplotterA.plot_tracks(set(tracksA), [0, 2], uncertainty=True)\nplotterA.fig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The resulting plot is exactly the same as Tutorial 2.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Run optimised brute force sensor manager\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Start timer for cell execution time\ncell_start_time2 = time.time()\n\nfor timestep in timesteps[1:]:\n\n    # Generate chosen configuration\n    chosen_actions = optimizebrutesensormanager.choose_actions(tracksB, timestep)\n\n    # Create empty dictionary for measurements\n    measurementsB = []\n\n    for chosen_action in chosen_actions:\n        for sensor, actions in chosen_action.items():\n            sensor.add_actions(actions)\n\n    for sensor in sensor_setB:\n        sensor.act(timestep)\n\n        # Observe this ground truth\n        measurements = sensor.measure(OrderedSet(truth[timestep] for truth in truths), noise=True)\n        measurementsB.extend(measurements)\n\n    hypotheses = data_associator.associate(tracksB,\n                                           measurementsB,\n                                           timestep)\n    for track in tracksB:\n        hypothesis = hypotheses[track]\n        if hypothesis.measurement:\n            post = updater.update(hypothesis)\n            track.append(post)\n        else:  # When data associator says no detections are good enough, we'll keep the prediction\n            track.append(hypothesis.prediction)\n\ncell_run_time2 = round(time.time() - cell_start_time2, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot ground truths, tracks and uncertainty ellipses for each target.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plotterB = Plotterly()\nplotterB.plot_sensors(sensor_setB)\nplotterB.plot_ground_truths(truths_set, [0, 2])\nplotterB.plot_tracks(set(tracksB), [0, 2], uncertainty=True)\nplotterB.fig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Run optimised basin hopping sensor manager\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Start timer for cell execution time\ncell_start_time3 = time.time()\n\nfor timestep in timesteps[1:]:\n\n    # Generate chosen configuration\n    chosen_actions = optimizebasinhoppingsensormanager.choose_actions(tracksC, timestep)\n\n    # Create empty dictionary for measurements\n    measurementsC = []\n\n    for chosen_action in chosen_actions:\n        for sensor, actions in chosen_action.items():\n            sensor.add_actions(actions)\n\n    for sensor in sensor_setC:\n        sensor.act(timestep)\n\n        # Observe this ground truth\n        measurements = sensor.measure(OrderedSet(truth[timestep] for truth in truths), noise=True)\n        measurementsC.extend(measurements)\n\n    hypotheses = data_associator.associate(tracksC,\n                                           measurementsC,\n                                           timestep)\n    for track in tracksC:\n        hypothesis = hypotheses[track]\n        if hypothesis.measurement:\n            post = updater.update(hypothesis)\n            track.append(post)\n        else:  # When data associator says no detections are good enough, we'll keep the prediction\n            track.append(hypothesis.prediction)\n\ncell_run_time3 = round(time.time() - cell_start_time3, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot ground truths, tracks and uncertainty ellipses for each target.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plotterC = Plotterly()\nplotterC.plot_sensors(sensor_setC)\nplotterC.plot_ground_truths(truths_set, [0, 2])\nplotterC.plot_tracks(set(tracksC), [0, 2], uncertainty=True)\nplotterC.fig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "At first glance, the plots for each of the optimised sensor managers show a very\nsimilar tracking performance to the :class:`~.BruteForceSensorManager`.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Metrics\n\nAs in Tutorials 1 & 2 the SIAP and uncertainty metrics are used to compare\nthe tracking performance of the sensor managers in more detail.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.metricgenerator.tracktotruthmetrics import SIAPMetrics\nfrom smartfusion.measures import Euclidean\nsiap_generator = SIAPMetrics(position_measure=Euclidean((0, 2)),\n                             velocity_measure=Euclidean((1, 3)))\n\nfrom smartfusion.dataassociator.tracktotrack import TrackToTruth\nassociator = TrackToTruth(association_threshold=30)\n\nfrom smartfusion.metricgenerator.uncertaintymetric import SumofCovarianceNormsMetric\nuncertainty_generator = SumofCovarianceNormsMetric()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate a metric manager for each sensor management method.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.metricgenerator.manager import SimpleManager\n\nmetric_managerA = SimpleManager([siap_generator, uncertainty_generator],\n                                associator=associator)\n\nmetric_managerB = SimpleManager([siap_generator, uncertainty_generator],\n                                associator=associator)\n\nmetric_managerC = SimpleManager([siap_generator, uncertainty_generator],\n                                associator=associator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For each time step, data is added to the metric manager on truths and tracks.\nThe metrics themselves can then be generated from the metric manager.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "metric_managerA.add_data(truths, tracksA)\nmetric_managerB.add_data(truths, tracksB)\nmetric_managerC.add_data(truths, tracksC)\n\nmetricsA = metric_managerA.generate_metrics()\nmetricsB = metric_managerB.generate_metrics()\nmetricsC = metric_managerC.generate_metrics()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SIAP metrics\n\nFirst we look at SIAP metrics. We are only interested in the positional accuracy (PA) and\nvelocity accuracy (VA). These metrics can be plotted to show how they change over time.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n\nfig, axes = plt.subplots(2)\n\ntimes = metric_managerA.list_timestamps()\n\npa_metricA = metricsA['SIAP Position Accuracy at times']\nva_metricA = metricsA['SIAP Velocity Accuracy at times']\n\npa_metricB = metricsB['SIAP Position Accuracy at times']\nva_metricB = metricsB['SIAP Velocity Accuracy at times']\n\npa_metricC = metricsC['SIAP Position Accuracy at times']\nva_metricC = metricsC['SIAP Velocity Accuracy at times']\n\naxes[0].set(title='Positional Accuracy', xlabel='Time', ylabel='PA')\naxes[0].plot(times, [metric.value for metric in pa_metricA.value],\n             label='BruteForceSensorManager')\naxes[0].plot(times, [metric.value for metric in pa_metricB.value],\n             label='OptimizeBruteSensorManager')\naxes[0].plot(times, [metric.value for metric in pa_metricC.value],\n             label='OptimizeBasinHoppingSensorManager')\naxes[0].legend()\n\naxes[1].set(title='Velocity Accuracy', xlabel='Time', ylabel='VA')\naxes[1].plot(times, [metric.value for metric in va_metricA.value],\n             label='BruteForceSensorManager')\naxes[1].plot(times, [metric.value for metric in va_metricB.value],\n             label='OptimizeBruteSensorManager')\naxes[1].plot(times, [metric.value for metric in va_metricC.value],\n             label='OptimizeBasinHoppingSensorManager')\naxes[1].legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Both graphs show that there is little performance difference between the different sensor managers.\nPositional accuracy remains consistently good and velocity accuracy improves after overcoming\nthe initial differences in the priors.\n\n### Uncertainty metric\n\nNext we look at the uncertainty metric which computes the sum of covariance matrix norms of each state at each\ntime step. This is plotted over time for each sensor manager method.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "uncertainty_metricA = metricsA['Sum of Covariance Norms Metric']\nuncertainty_metricB = metricsB['Sum of Covariance Norms Metric']\nuncertainty_metricC = metricsC['Sum of Covariance Norms Metric']\n\nfig = plt.figure()\nax = fig.add_subplot(1, 1, 1)\nax.plot([i.timestamp for i in uncertainty_metricA.value],\n        [i.value for i in uncertainty_metricA.value],\n        label='BruteForceSensorManager')\nax.plot([i.timestamp for i in uncertainty_metricB.value],\n        [i.value for i in uncertainty_metricB.value],\n        label='OptimizeBruteSensorManager')\nax.plot([i.timestamp for i in uncertainty_metricC.value],\n        [i.value for i in uncertainty_metricC.value],\n        label='OptimizeBasinHoppingSensorManager')\nax.set_ylabel(\"Sum of covariance matrix norms\")\nax.set_xlabel(\"Time\")\nax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The uncertainty metric shows some variation between the sensor management methods,\nwith a little more variation in the basin hopping method than the brute force methods.\nOverall they have a similar performance, improving after overcoming the initial\ndifferences in the priors.\n\n### Cell runtime\n\nNow let us compare the calculated runtime of the tracking loop for each of the sensor managers.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\nax = fig.add_subplot(1, 1, 1)\nax.set_ylabel('Cell run time (s)')\nax.bar(['Brute Force', 'Optimised Brute Force', 'Optimised Basin Hopping'],\n       [cell_run_time1, cell_run_time2, cell_run_time3],\n       color=['tab:blue', 'tab:orange', 'tab:green'])\n\nprint(f'Brute Force: {cell_run_time1} s')\nprint(f'Optimised Brute Force: {cell_run_time2} s')\nprint(f'Optimised Basin Hopping: {cell_run_time3} s')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These run times show that each of the optimised methods are significantly quicker than the brute force method\nwhilst maintaining a similar tracking performance. This difference becomes more clear when the complexity of\nthe situation increases - by including additional sensors for example.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n\n.. [#] *Votruba, Paul & Nisley, Rich & Rothrock, Ron and Zombro, Brett.*, **Single Integrated Air\n   Picture (SIAP) Metrics Implementation**, 2001\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}