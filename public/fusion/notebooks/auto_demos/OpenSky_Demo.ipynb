{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Tracking Groundtruth ADS-B Data by Simulating Radar Detections\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction\nOur goal in this demonstration is to plot time series data of SMART FUSION's :class:`~.MultiTargetTracker`\nbeing applied to air traffic over and surrounding the UK.\nWe will establish the individual components required for our tracker, including simulating radar\ndetection data from our groundtruth, which will be read in from a CSV file of ADS\u2013B data sourced\nfrom `The OpenSky Network`_ [#]_ [#]_. Finally, we will plot our tracks using the Folium plugin\n`TimestampedGeoJson`_.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reading the CSV File\nTo read in our groundtruth data from a CSV file, we can use SMART FUSION\u2019s\n:class:`~.CSVGroundTruthReader`. To convert our longitude and latitude data to Universal\nTransverse Mercator (UTM) projection, we will use :class:`~.LongLatToUTMConverter`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.reader.generic import CSVGroundTruthReader\nfrom smartfusion.feeder.geo import LongLatToUTMConverter\nimport utm\n\ntruthslonlat = CSVGroundTruthReader(\n    \"OpenSky_Plane_States.csv\",\n    state_vector_fields=(\"lon\", \"x_speed\", \"lat\", \"y_speed\",\n                         \"geoaltitude\", \"vertrate\"),  # List of columns names to be used in state vector\n    path_id_field=\"icao24\",                           # Name of column to be used as path ID\n    time_field=\"time\",                                # Name of column to be used as time field\n    timestamp=True)                                   # Treat time field as a timestamp from epoch\n\n\ngroundtruth = LongLatToUTMConverter(truthslonlat, zone_number=30,  mapping=[0, 2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Constructing Sensors\nNow we will assemble our sensors used in this demonstration. We\u2019ll introduce 2 stationary radar\nsensors, and also demonstrate SMART FUSION\u2019s ability to model moving sensors.\n\nWe will use :class:`~.RadarElevationBearingRange` to establish our radar sensors.\n:class:`~.RadarElevationBearingRange` allows us to generate measurements of targets by using\na :class:`~.CartesianToElevationBearingRange` model. We proceed to create a :class:`~.Platform`\nfor each stationary sensor, and append these to our list of all platforms.\n\nOur moving sensor will be created similarly to the stationary case. We will need to\nmake a movement controller to control the platform's movement, this is done by creating\ntransition models, as well as setting transition times.\n\n:class:`~.PlatformDetectionSimulator` will then proceed to generate our detection data from\nthe groundtruth (calls each sensor in platforms).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import datetime\nimport numpy as np\n\nfrom smartfusion.types.array import StateVector\nfrom smartfusion.sensor.radar import RadarElevationBearingRange\nfrom smartfusion.types.state import State\nfrom smartfusion.platform.base import FixedPlatform, MultiTransitionMovingPlatform\nfrom smartfusion.simulator.platform import PlatformDetectionSimulator\nfrom smartfusion.models.transition.linear import CombinedLinearGaussianTransitionModel,\\\n    ConstantVelocity, KnownTurnRate\n\n# Create locations for reference later\n\n# Using Heathrow as origin\n*heathrow, utm_zone, _ = utm.from_latlon(51.47, -0.4543)\n# Use heathrow utm grid num as reference number for utm conversions later\nmanchester = utm.from_latlon(53.35, -2.280, utm_zone)\n\n\n# Create transition models for moving platforms\ntransition_modelStraight = CombinedLinearGaussianTransitionModel((ConstantVelocity(0.01),\n                                                                  ConstantVelocity(0.01),\n                                                                  ConstantVelocity(0.01)))\n\ntransition_modelLeft = CombinedLinearGaussianTransitionModel((KnownTurnRate((0.01, 0.01),\n                                                              np.radians(3)), ConstantVelocity(0.01)))\n\n\n# Create specific transition model for example moving platform\ntransition_models = [transition_modelStraight,\n                     transition_modelLeft]\ntransition_times = [datetime.timedelta(seconds=160),\n                    datetime.timedelta(seconds=20)]\n\n\n# List sensors in stationary platforms\nstationarySensors = [\n    RadarElevationBearingRange(\n        ndim_state=6,\n        position_mapping=(0, 2, 4),\n        noise_covar=np.diag([np.radians(1)**2, np.radians(1)**2, 7**2]),\n        max_range=100000),\n\n    RadarElevationBearingRange(\n        ndim_state=6,\n        position_mapping=(0, 2, 4),\n        noise_covar=np.diag([np.radians(1)**2, np.radians(1)**2, 7**2]),\n        max_range=100000)\n    ]\n\n# List sensors in moving platform\nmovingPlatformSensors = [\n    RadarElevationBearingRange(\n        ndim_state=6,\n        position_mapping=(0, 2, 4),\n        noise_covar=np.diag([np.radians(1.2)**2, np.radians(1.2)**2, 8**2]),\n        max_range=60000)\n    ]\n\nplatforms = []\n\n# Create a platform for each stationary sensor and add to list of platforms\nfor sensor, platformLocation in zip(stationarySensors, (heathrow, manchester)):\n    platformState = State([[platformLocation[0]], [0], [platformLocation[1]], [0], [0], [0]])\n    platform = FixedPlatform(platformState, (0, 2, 4), sensors=[sensor])\n    platforms.append(platform)\n\n# Create moving platform\nmovingPlatformInitialLocation = utm.from_latlon(52.25, -0.9, utm_zone)\nmovingPlatformState = State([[movingPlatformInitialLocation[0]], [0],\n                             [movingPlatformInitialLocation[1]], [250], [5000], [0]])\nmovingPlatforms = [MultiTransitionMovingPlatform(movingPlatformState,\n                                                 position_mapping=(0, 2, 4),\n                                                 transition_models=transition_models,\n                                                 transition_times=transition_times,\n                                                 sensors=movingPlatformSensors)]\n\n# Add moving platform to list of platforms\nplatforms.extend(movingPlatforms)\n\n# Simulate platform detections\ndetection_sim = PlatformDetectionSimulator(groundtruth, platforms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Individual Components\nNow it's time to set up our individual components needed to construct our initiator, and\nultimately our :class:`~.MultiTargetTracker`. We will be using the Extended Kalman Filter\nsince our sensor model, :class:`~.CartesianToElevationBearingRange`, is not linear.\n\nTo produce our linear transition model, we combine multiple one dimensional models into one\nsingular model. Notice how we specify a different transition model for our initiator. We then\npass these transition models to their respective predictors.\nThe update step calculates the posterior state estimate by using both our prediction and\nsensor measurement. We don't need to define the measurement model here since the\nmodel :class:`~.CartesianToElevationBearingRange` is already provided in the measurements.\n\nThe :class:`~.DistanceHypothesiser` generates track predictions at detection times, and\nscores each hypothesised prediction-detection pair using our set measure of :class:`~.Mahalanobis`\ndistance. We allocate the detections to our predicted states by using the Global Nearest Neighbour\nmethod. The :class:`~.UpdateTimeDeleter` will identify the tracks for deletion and delete them\nonce the time since last update has exceeded our specified time.\nBy having `delete_last_pred = True`, the state that caused a track to be deleted will be deleted\n(if it is a prediction).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "transition_model = CombinedLinearGaussianTransitionModel(\n    (ConstantVelocity(20), ConstantVelocity(20), ConstantVelocity(2)))\ninit_transition_model = CombinedLinearGaussianTransitionModel(\n    (ConstantVelocity(5), ConstantVelocity(5), ConstantVelocity(2)))\n\nfrom smartfusion.predictor.kalman import ExtendedKalmanPredictor\npredictor = ExtendedKalmanPredictor(transition_model)\ninit_predictor = ExtendedKalmanPredictor(init_transition_model)\n\nfrom smartfusion.updater.kalman import ExtendedKalmanUpdater\nupdater = ExtendedKalmanUpdater(measurement_model=None)\n\nfrom smartfusion.hypothesiser.distance import DistanceHypothesiser\nfrom smartfusion.measures import Mahalanobis\nhypothesiser = DistanceHypothesiser(predictor, updater, Mahalanobis(), missed_distance=5)\n\nfrom smartfusion.dataassociator.neighbour import GNNWith2DAssignment\ndata_associator = GNNWith2DAssignment(hypothesiser)\n\nfrom smartfusion.deleter.time import UpdateTimeDeleter\ndeleter = UpdateTimeDeleter(datetime.timedelta(seconds=20), delete_last_pred=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The Initiator\nWe can now create the initiator. The :class:`~.MultiMeasurementInitiator` will initiate\nand hold tracks until enough detections have been associated with the track. It will then\nproceed to release the tracks to the tracker.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.initiator.simple import MultiMeasurementInitiator\nfrom smartfusion.types.state import GaussianState\n\ninitiator = MultiMeasurementInitiator(\n    GaussianState(\n        np.array([[0], [0], [0], [0], [0], [0]]),   # Prior State\n        np.diag([15**2, 100**2, 15**2, 100**2, 15**2, 20**2])),\n    measurement_model=None,\n    deleter=deleter,\n    data_associator=GNNWith2DAssignment(\n        DistanceHypothesiser(init_predictor, updater, Mahalanobis(), missed_distance=3)),\n    updater=updater,\n    min_points=2\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The Tracker\nNext, we bring together all the components we\u2019ve assembled to construct our :class:`~.MultiTargetTracker`.\nA loop is created to generate tracks at each time interval, and store them in a set called tracks.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.tracker.simple import MultiTargetTracker\n\nkalman_tracker = MultiTargetTracker(\n    initiator=initiator,\n    deleter=deleter,\n    detector=detection_sim,\n    data_associator=data_associator,\n    updater=updater,\n)\n\ntracks = set()\nfor step, (time, current_tracks) in enumerate(kalman_tracker, 1):\n    tracks.update(current_tracks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It's easy for us to see how many tracks we've created by checking the length of the set tracks.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "len(tracks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting\nWe will be using the Folium plotting library so we can visualize our tracks on a two-dimensional\nleaflet map. These Folium markers will show where our stationary sensors are located. Since our\nFOV angles are 360 degrees, we can easily use a fixed circle to display our radar's coverage.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import folium\n\nm = folium.Map(\n    location=[52.41, -0.4543], zoom_start=6)\n\nfolium.TileLayer('openstreetmap').add_to(m)\n\n\nfolium.Marker([51.47, -0.4543],\n              tooltip=\"Heathrow Airport\",\n              icon=folium.Icon(icon='fa-circle', prefix=\"fa\",      # Marker for Heathrow\n              color=\"red\")).add_to(m)\n\nfolium.Marker([53.35, -2.280],\n              tooltip=\"Manchester Airport\",\n              icon=folium.Icon(icon='fa-circle', prefix=\"fa\",      # Marker for Manchester\n              color=\"green\")).add_to(m)\n\n\nfolium.Circle(location=[51.47, -0.4543],\n              popup='',\n              fill_color='#000',                  # radar for Heathrow\n              radius=100000,\n              weight=2,\n              color=\"#000\").add_to(m)\n\n\nfolium.Circle(location=[53.35, -2.280],\n              popup='',\n              fill_color='#000',\n              radius=100000,                     # radar for Manchester\n              weight=2,\n              color=\"#000\").add_to(m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GeoJSON\nThe Folium plugin `TimestampedGeoJson`_ will be used to plot our tracks using timestamped\nGeoJSONs. As a result, we want to convert our data into `GeoJSON format`_. Firstly, we create\nour feature collection which we will append our features to.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "geo_features = list()\ngeo_json = {\n    'type': \"FeatureCollection\",\n    'features': geo_features,\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each feature will have a properties object and a geometry object. Our properties object\nwill contain information on the icon, popup, timestamps etc. The geometry object will be\neither a LineString, (for tracks and groundtruth path), or a MultiPoint (for icons of planes\nand moving sensor).\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plotting the Moving Sensor\nLet us set up the icon and trail for our moving sensor. A radar dish icon [#images]_ will show its location\nat any given timestamp, and its trail will show where it has been.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trail_Size = 14  # trail_Size is number of timestamps we want track to trail for\nfor platform in movingPlatforms:\n    points = []\n    times_Sensor = []  # list of timestamps moving sensor has existed for.\n\n    for state in platform.last_timestamp_generator():\n        points.append( utm.to_latlon(state.state_vector[0], state.state_vector[2], utm_zone,\n                                     northern=True, strict=False)[::-1])\n\n        times_Sensor.append(state.timestamp.strftime('%Y-%m-%d %H:%M:%S'))\n\n    for time_index, time in enumerate(times_Sensor):\n        geo_features.append({  # attaching info about moving sensor to geo_json\n            'type': \"Feature\",\n            'properties':\n                {'popup':  \"Moving Sensor\",\n                'name':   '',\n                'style':  {'color': 'black', 'weight': 4},\n                'times':  [time]*trail_Size},\n\n            'geometry':\n                {'type': \"LineString\",\n                'coordinates': points[:time_index+1][-trail_Size:]}\n        })\n\n        geo_features.append({  # attaching icon info about moving sensor to geo_json\n            'type': \"Feature\",\n            'properties':{\n                'icon': 'marker',\n                'iconstyle':{\n                    'iconUrl': '../_static/sphinx_gallery/Radar_dish.png',\n                    'iconSize': [24, 24],\n                    'fillOpacity': 1,\n                    'popupAnchor': [1, -17]},\n\n                'popup': \"Moving Sensor\",\n                'name':  '',\n                'style': {'color': 'black', 'weight': 4},\n                'times': [time]},\n\n            'geometry':{\n                'type': \"MultiPoint\",\n                'coordinates': [points[time_index]]}\n        })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We also want to display our moving sensor\u2019s FOV as time progresses.\nSince GeoJSON does not support circles, we will display the boundary of our moving sensor's\nFOV by drawing a LineString.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "points_ = []  # setting up points for moving sensor (UTM)\nradius = 60000  # 60 km, radius of our moving sensor\npolygon_Sides = 60\nfor state in movingPlatforms:\n    for time_index, time in enumerate(times_Sensor): # num_Timestamps = number of timestamps elapsed\n        points_.append((state[time_index].state_vector[0], state[time_index].state_vector[2]))\n\n    for (time_index,(x, y)) in enumerate(points_):  # finding points of circle\n        time = times_Sensor[time_index]             # for range of moving sensor.\n        angles = np.linspace(0, 2 * np.pi, polygon_Sides + 1, endpoint=True)\n\n        points_list = [utm.to_latlon(x + np.sin(angle) * radius,\n                       y + np.cos(angle) * radius, utm_zone, northern=True, strict=False)[::-1]\n                       for angle in angles]\n\n        geo_features.append({\n            'type': \"Feature\",\n            'properties':{\n                'popup':  \"Moving Sensor FOV\",\n                'name':    '',\n                'style':   {'color': 'black', 'weight': 3},\n                'times':   [time] * (polygon_Sides + 1)},\n\n            'geometry':{\n                'type':   \"LineString\",\n                'coordinates': points_list}\n        })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plotting Tracks\nNow we append our tracks to our feature collection list. We define `colour_iter` which will\nallow us to cycle through different colours when mapping our tracks.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\nfrom itertools import cycle\n\ncolour_iter = iter(cycle(\n    ['red', 'blue', 'green', 'purple', 'orange', 'darkred',\n     '#0909FF','#F70D1A', '#FF6700', 'lightgreen', '#0AFFFF',\n     '#12AD2B', '#E2F516', '#FFFF00', '#F52887']))\ncolour = defaultdict(lambda: next(colour_iter))\n\ntrail_Size = 14  # trail_Size is the number of timestamps we want track to trail for\n\nfor track in tracks:\n    plot_times = [state.timestamp.strftime('%Y-%m-%d %H:%M:%S')\n                  for state in track.last_timestamp_generator()]\n\n    plot_points = [\n        utm.to_latlon(state.state_vector[0], state.state_vector[2], utm_zone, northern=True,\n                      strict=False)[::-1] for state in track.last_timestamp_generator()]\n\n    for time_index, time in enumerate(plot_times):\n        geo_features.append({\n            'type': \"Feature\",\n            'properties':{\n                'name':  track.id,\n                'style': {'color': colour[track], 'weight': 6},\n                'times': [time] * len(plot_points[:time_index+1][-trail_Size:])},\n\n            'geometry':{\n                'type': \"LineString\",\n                'coordinates': plot_points[:time_index+1][-trail_Size:]}\n        })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plotting Groundtruth\nTo plot our groundtruth, we firstly want to set up a dictionary that will allow us to easily\naccess our groundtruth data. The dictionary will enable us to get data in the correct format\nneeded for plotting, as well as for displaying key properties on popups.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "all_truths = dict()\nfor time, truths in truthslonlat:\n    for truth in truths:\n        id_ = truth.metadata.get('icao24')\n        if id_ not in all_truths:\n            all_truths[id_] = dict()\n            all_truths[id_]['times'] = list()\n            all_truths[id_]['lonlats'] = list()\n            all_truths[id_]['velocity'] = list()\n            all_truths[id_]['heading'] = list()\n        lon, lat = truth.state_vector[[0, 2]]\n        all_truths[id_]['times'].append(time)\n        all_truths[id_]['lonlats'].append((lon, lat))\n        all_truths[id_]['velocity'].append(truth.metadata.get('velocity'))\n        all_truths[id_]['heading'].append(truth.metadata.get('heading'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A list of all icao24 addresses in our data will also be created. These addresses are used to\ngive an aircraft a unique identity. We will run through this list and use our groundtruth\ndictionary to get relevant data needed for plotting.\nThe variable `trail_Size` will determine how much history of the track we want to be seen.\nWe will plot a LineString to display our track, taking into account our specified `trail_Size`\nto determine the cut-off point.\n\nWe begin with creating the trails of our groundtruth.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "icao = list()\nfor time, truths in truthslonlat:\n    for truth in truths:\n        ids = truth.metadata.get('icao24')\n        if ids not in icao:\n            icao.append(ids)\n\nfor id in icao:\n    trail_Size = 14\n    for time_index, time in enumerate(all_truths[id]['times']):\n        points=all_truths[id]['lonlats'][:time_index+1][-trail_Size:]\n        geo_features.append({\n            'type': \"Feature\",\n            'properties':{\n                'name': '',\n                'style': {'color': 'black', 'weight': 2},\n                'times': [time.strftime('%Y-%m-%d %H:%M:%S')]*len(points)},\n\n            'geometry':{\n                'type': \"LineString\",\n                'coordinates': points}\n                            })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our final task is to provide icons for our groundtruth. For each timestamp, each plane's\nheading will be rounded to the nearest 10 degrees, and an appropriate icon [#images]_ to reflect this\nheading will be chosen. Icons of planes can also be clicked on to display key data\n(remember to pause time to do this).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for id in icao:\n    for time in range(len(all_truths[id]['times'])):\n        if all_truths[id]['heading'][time] == '':  # if no heading given in data,\n            break                                  # won't plot icon\n\n        angle = round(float(all_truths[id]['heading'][time]), -1) # rounding angle to nearest 10 degrees\n        if angle == 360:\n            angle = 0\n        angle = int(angle)\n\n        geo_features.append({\n            'type': \"Feature\",\n            'properties':{\n                'icon': 'marker',\n                'iconstyle':{\n                    'iconUrl': f'../_static/sphinx_gallery/Plane_Headings/Plane_{angle}.png',\n                    'iconSize': [24, 24],\n                    'fillOpacity': 1,\n                    'popupAnchor': [1, -17],\n\n                                         },\n\n                'popup':\n                     \"ICAO24: \" + id + \"<dd>\"\n       \n                     \"Velocity: \" + '%s' % float('%.5g' %\n                     (float(all_truths[id]['velocity'][time]))) + \" m/s\" + \"<dd>\"\n                                                                     \n                     \"Heading: \" + '%s' % float('%.5g' %\n                     (float(all_truths[id][\"heading\"][time]))) + \"\u00b0\" + \"<dd>\" \n                                                                            \n                     \"Longitude: \" + '%s' % float('%.8g' %\n                     (all_truths[id][\"lonlats\"][time][0])) + \"<dd>\" # rounding 8 sigfigs\n\n                     \"Latitude: \" + '%s' % float('%.8g' %\n                     (all_truths[id][\"lonlats\"][time][1])),\n\n                'name': '',\n                'style': {'color': 'black', 'weight': 2},\n                'times': [all_truths[id]['times'][time].strftime('%Y-%m-%d %H:%M:%S')]},\n\n            'geometry':{\n                'type': \"MultiPoint\",\n                'coordinates': [all_truths[id]['lonlats'][time]]}\n        })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The Results\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from folium.plugins import TimestampedGeoJson, Fullscreen\n\nFullscreen().add_to(m)\n\nTimestampedGeoJson(\n    data=geo_json,\n    transition_time=200,\n    auto_play=True,\n    add_last_point=False,\n    period='PT10S',\n    duration='PT0S').add_to(m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n.. [#] The OpenSky Network, http://www.opensky-network.org\n.. [#] Bringing up OpenSky: A large-scale ADS-B sensor network for research\n   Matthias Sch\u00e4fer, Martin Strohmeier, Vincent Lenders, Ivan Martinovic, Matthias Wilhelm\n   ACM/IEEE International Conference on Information Processing in Sensor Networks, April 2014\n.. [#images] Radar and Plane icons provided by http://simpleicon.com/\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}