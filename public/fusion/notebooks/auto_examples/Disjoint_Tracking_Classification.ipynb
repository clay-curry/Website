{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Disjoint Tracking and Classification\nThis is a demonstration of a utilisation of the implemented Hidden Markov model and composite\ntracking modules in order to categorise a target as well as track its kinematics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "All non-generic imports will be given in order of usage.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from datetime import datetime, timedelta\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom smartfusion.models.transition.linear import ConstantVelocity, \\\n    CombinedLinearGaussianTransitionModel\nfrom smartfusion.types.groundtruth import GroundTruthState"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ground Truth, Categorical and Composite States\nWe will attempt to track and classify 3 targets.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### True Kinematics\nThey will move in random directions from defined starting points.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "start = datetime.now()\n\nkinematic_state1 = GroundTruthState([0, 1, 0, 1], timestamp=start)  # x, vx, y, vy\nkinematic_state2 = GroundTruthState([10, -1, 0, 1], timestamp=start)\nkinematic_state3 = GroundTruthState([10, -1, 5, 1], timestamp=start)\n\nkinematic_transition = CombinedLinearGaussianTransitionModel([ConstantVelocity(0.1),\n                                                              ConstantVelocity(0.1)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### True Classifications\nA target may take one of three discrete hidden classes: 'bike', 'car' and 'bus'.\nIt will be assumed that the targets cannot transition from one class to another, hence an\nidentity transition matrix is given to the :class:`~.MarkovianTransitionModel` for all targets.\n\nA :class:`~.CategoricalState` class is used to store information on the classification/'category'\nof the targets. The state vector of each will define a categorical distribution over the 3\npossible classes, whereby each component defines the probability that the target is of the\ncorresponding class. For example, the state vector (0.2, 0.3, 0.5), with category names\n('bike', 'car', 'bus') indicates that the target has a 20% probability of being class\n'bike', a 30% probability of being class 'car' etc.\nIt does not make sense to have a true target being a distribution over the possible classes, and\ntherefore the true categorical states will have binary state vectors indicating a specific class\nfor each target (i.e. a '1' at one state vector index, and '0's elsewhere).\nThe :class:`~.CategoricalGroundTruthState` inherits directly from the base\n:class:`~.CategoricalState`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.types.groundtruth import CategoricalGroundTruthState\nfrom smartfusion.models.transition.categorical import MarkovianTransitionModel\n\nhidden_classes = ['bike', 'car', 'bus']\ngt_kwargs = {'timestamp': start, 'categories': hidden_classes}\ncategory_state1 = CategoricalGroundTruthState([0, 0, 1], **gt_kwargs)\ncategory_state2 = CategoricalGroundTruthState([1, 0, 0], **gt_kwargs)\ncategory_state3 = CategoricalGroundTruthState([0, 1, 0], **gt_kwargs)\n\ncategory_transition = MarkovianTransitionModel(transition_matrix=np.eye(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Composite States\nEach target will have kinematics and a category to be inferred. These are contained within a\n:class:`~.CompositeState` type (in this instance the child class\n:class:`~.CompositeGroundTruthState`).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.types.groundtruth import CompositeGroundTruthState\n\ninitial_state1 = CompositeGroundTruthState([kinematic_state1, category_state1])\ninitial_state2 = CompositeGroundTruthState([kinematic_state2, category_state2])\ninitial_state3 = CompositeGroundTruthState([kinematic_state3, category_state3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generating Ground Truth Paths\nBoth the physical and categorical states of the targets need to be transitioned. While the\ncategory will remain the same, a transition model is used here for the sake of demonstration.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.types.groundtruth import GroundTruthPath\n\nGT1 = GroundTruthPath([initial_state1], id='GT1')\nGT2 = GroundTruthPath([initial_state2], id='GT2')\nGT3 = GroundTruthPath([initial_state3], id='GT3')\nground_truth_paths = [GT1, GT2, GT3]\n\nfor GT in ground_truth_paths:\n    for i in range(10):\n        kinematic_sv = kinematic_transition.function(GT[-1][0],\n                                                     noise=True,\n                                                     time_interval=timedelta(seconds=1))\n        kinematic = GroundTruthState(kinematic_sv,\n                                     timestamp=GT[-1].timestamp + timedelta(seconds=1))\n\n        category_sv = category_transition.function(GT[-1][1],\n                                                   noise=True,\n                                                   time_interval=timedelta(seconds=1))\n        category = CategoricalGroundTruthState(category_sv,\n                                               timestamp=GT[-1].timestamp + timedelta(seconds=1),\n                                               categories=hidden_classes)\n\n        GT.append(CompositeGroundTruthState([kinematic, category]))\n\n# Printing GT1\nfor state in GT1:\n    vector = np.round(state[0].state_vector.flatten().astype(np.double), 2)\n    print(\"%25s\" % vector, ' -- ', state[1].category, ' -- ', state.timestamp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plotting Ground Truths\nColour will be used in plotting as an indicator to category: red == 'bike', green == 'car',\nblue == 'bus'.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 3, figsize=(10, 5))\nfig.set_figheight(15)\nfig.set_figwidth(15)\nfig.subplots_adjust(wspace=5)\nfig.tight_layout()\n\nfor ax in axes:\n    ax.set_aspect('equal', 'box')\n\nfor GT in ground_truth_paths:\n    X = list()\n    Y = list()\n    col = list(GT[0][1].state_vector)\n    for state in GT:\n        pos = state[0].state_vector\n        X.append(pos[0])\n        Y.append(pos[2])\n    axes[0].plot(X, Y, color=col, label=GT[-1][1].category)\naxes[0].legend(loc='upper left')\naxes[0].set(title='GT', xlabel='X', ylabel='Y')\naxes[1].set_visible(False)\naxes[2].set_visible(False)\n\n\ndef set_axes_limits():\n    xmax = max(ax.get_xlim()[1] for ax in axes)\n    ymax = max(ax.get_ylim()[1] for ax in axes)\n    xmin = min(ax.get_xlim()[0] for ax in axes)\n    ymin = min(ax.get_ylim()[0] for ax in axes)\n    for ax in axes:\n        ax.set_xlim(xmin, xmax)\n        ax.set_ylim(ymin, ymax)\n\n\nset_axes_limits()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Measurement\nA new sensor will be created, that can provide the information needed to both track and classify\nthe targets.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Composite Detection\nDetections relating to both the kinematics and classification will be needed. Therefore we will\ncreate a sensor that outputs :class:`~.CompositeDetection` types. The input `sensors` list will\nprovide the contents of these compositions. For this example we will provide a\n:class:`~.RadarBearingRange` and a :class:`~.HMMSensor` for kinematics and classification\nrespectively.\n:class:`~.CompositeDetection` types have a `mapping` attribute, which defines what sub-state\nindex each sub-detection was created from. For example, with a composite state of form:\n(kinematic state, categorical state), and composite detection with mapping (1, 0), this would\nindicate that the 0th index sub-detection was attained from the categorical state, and the 1st\nindex sub-detection from the kinematic state.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from typing import Set, Union, Sequence\n\nfrom smartfusion.base import Property\nfrom smartfusion.sensor.sensor import Sensor\nfrom smartfusion.types.detection import CompositeDetection\n\n\nclass CompositeSensor(Sensor):\n    sensors: Sequence[Sensor] = Property(doc=\"A list of sensors.\")\n    mapping: Sequence = Property(default=None,\n                                 doc=\"Mapping of which component states in the composite truth \"\n                                     \"state is measured.\")\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        if self.mapping is None:\n            self.mapping = list(np.arange(len(self.sensors)))\n\n    def measure(self, ground_truths: Set[CompositeGroundTruthState],\n                noise: Sequence[Union[np.ndarray, bool]] = True,\n                **kwargs) -> Set[CompositeDetection]:\n\n        if isinstance(noise, bool) or len(noise) == 1:\n            noise = len(self.sensors) * [noise]\n\n        detections = set()\n        for truth in ground_truths:\n\n            sub_detections = list()\n\n            states = [truth.sub_states[i] for i in self.mapping]\n\n            for state, sub_sensor, sub_noise in zip(states, self.sensors, noise):\n                sub_detection = sub_sensor.measure(\n                    ground_truths={state},\n                    noise=sub_noise\n                ).pop()  # sub-sensor returns a set\n                sub_detections.append(sub_detection)\n\n            detection = CompositeDetection(sub_states=sub_detections,\n                                           groundtruth_path=truth,\n                                           mapping=self.mapping)\n            detections.add(detection)\n\n        return detections\n\n    @property\n    def measurement_model(self):\n        raise NotImplementedError"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Kinematic Measurement\nMeasurements of the target's kinematics will be attained via a :class:`~.RadarBearingRange`\nsensor model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.sensor.radar.radar import RadarBearingRange\n\nradar = RadarBearingRange(ndim_state=4,\n                          position_mapping=[0, 2],\n                          noise_covar=np.diag([np.radians(0.05), 0.1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Categorical Measurement\nUsing the hidden Markov model, it is assumed the hidden class of the target cannot be directly\nobserved, and instead indirect observations are taken. In this instance, observations of the\ntarget's size are taken ('small' or 'large'), which have direct implications as to the target's\nhidden class, and this relationship is modelled by the `emission matrix` of the\n:class:`~.MarkovianMeasurementModel`, which is used by the :class:`~.HMMSensor` to\nprovide :class:`~.CategoricalDetection` types.\nWe will model this such that a 'bike' has a very small chance of being observed as a 'big'\ntarget. Similarly, a 'bus' will tend to appear as 'large'. Whereas, a 'car' has equal chance of\nbeing observed as either.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.models.measurement.categorical import MarkovianMeasurementModel\nfrom smartfusion.sensor.categorical import HMMSensor\n\nE = np.array([[0.99, 0.5, 0.01],  # P(small | bike), P(small | car), P(small | bus\n              [0.01, 0.5, 0.99]])\nmodel = MarkovianMeasurementModel(emission_matrix=E,\n                                  measurement_categories=['small', 'large'])\n\neo = HMMSensor(measurement_model=model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Composite Sensor\nCreating the composite sensor class.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sensor = CompositeSensor(sensors=[eo, radar], mapping=[1, 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generating Measurements\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "all_measurements = list()\n\nfor gts1, gts2, gts3 in zip(GT1, GT2, GT3):\n    measurements_at_time = sensor.measure({gts1, gts2, gts3})\n    timestamp = gts1.timestamp\n    all_measurements.append((timestamp, measurements_at_time))\n\n# Printing some measurements\nfor i, (time, measurements_at_time) in enumerate(all_measurements):\n    if i > 2:\n        break\n    print(f\"{time:%H:%M:%S}\")\n    for measurement in measurements_at_time:\n        vector = np.round(measurement.state_vector.flatten().astype(np.double), 2)\n        print(\"%25s\" % vector, ' -- ', measurement[0].category)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plotting Measurements\nColour will be used to indicate measurement category: orange == 'small', light-blue == 'large'.\nIt is expected that the bus will have mostly light-blue (large) measurements coinciding with its\nroute, the bike will have mostly orange (small), and the car a roughly even split of both.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for time, measurements in all_measurements:\n    for measurement in measurements:\n        loc = measurement[1].state_vector\n        obs = measurement[0].state_vector\n        col = list(measurement[0].measurement_model.emission_matrix.T @ obs)\n\n        phi = loc[0]\n        rho = loc[1]\n        x = rho * np.cos(phi)\n        y = rho * np.sin(phi)\n        axes[1].scatter(x, y, color=col, marker='x', s=100, label=measurement[0].category)\n\na = axes[1].get_legend_handles_labels()\nb = {l: h for h, l in zip(*a)}\nc = [*zip(*b.items())]\nd = c[::-1]\naxes[1].legend(*d, loc='upper left')\n\naxes[1].set(title='Measurements', xlabel='X', ylabel='Y')\naxes[1].set_visible(True)\nset_axes_limits()\nfig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tracking Components\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Predictor\nThough not used by the tracking components here, a :class:`~.CompositePredictor` will predict\nthe component states of a composite state forward, according to a list of sub-predictors.\n\nA :class:`~.HMMPredictor` specifically uses :class:`~.MarkovianTransitionModel` types to\npredict.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.predictor.kalman import KalmanPredictor\nfrom smartfusion.predictor.categorical import HMMPredictor\nfrom smartfusion.predictor.composite import CompositePredictor\n\nkinematic_predictor = KalmanPredictor(kinematic_transition)\ncategory_predictor = HMMPredictor(category_transition)\n\npredictor = CompositePredictor([kinematic_predictor, category_predictor])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Updater\nThe :class:`~.CompositeUpdater` composite updater will update each component sub-state according\nto a list of corresponding sub-updaters. It has no method to create measurement predictions.\nThis is instead handled on instantiation of :class:`~.CompositeHypothesis` types: the expected\narguments to the updater's `update` method.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.updater.kalman import ExtendedKalmanUpdater\nfrom smartfusion.updater.categorical import HMMUpdater\nfrom smartfusion.updater.composite import CompositeUpdater\n\nkinematic_updater = ExtendedKalmanUpdater()\ncategory_updater = HMMUpdater()\n\nupdater = CompositeUpdater(sub_updaters=[kinematic_updater, category_updater])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hypothesiser\nThe hypothesiser is a :class:`~.CompositeHypothesiser` type. It is in the data association step\nthat tracking and classification are combined: for each measurement, a hypothesis is created for\nboth a track's kinematic and categorical components. A :class:`~.CompositeHypothesis` type is\ncreated, which contains these sub-hypotheses, whereby its weight is equal to the product of the\nsub-hypotheses' weights. These sub-hypotheses should be probabilistic.\n\nThe :class:`CompositeHypothesiser` uses a list of sub-hypothesisers to create these\nsub-hypotheses, hence the sub-hypothesisers should also be probabilistic.\nIn this example we will define a hypothesiser that simply changes kinematic distance weights in\nto probabilities for hypothesising the kinematic sub-state of the track.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.measures import Mahalanobis\nfrom smartfusion.hypothesiser.distance import DistanceHypothesiser\nfrom smartfusion.types.hypothesis import SingleProbabilityHypothesis\nfrom smartfusion.types.multihypothesis import MultipleHypothesis\n\n\nclass ProbabilityHypothesiser(DistanceHypothesiser):\n    def hypothesise(self, track, detections, timestamp, **kwargs):\n        multi_hypothesis = super().hypothesise(track, detections, timestamp, **kwargs)\n        single_hypotheses = multi_hypothesis.single_hypotheses\n        prob_single_hypotheses = list()\n        for hypothesis in single_hypotheses:\n            prob_hypothesis = SingleProbabilityHypothesis(hypothesis.prediction,\n                                                          hypothesis.measurement,\n                                                          1 / hypothesis.distance,\n                                                          hypothesis.measurement_prediction)\n            prob_single_hypotheses.append(prob_hypothesis)\n        return MultipleHypothesis(prob_single_hypotheses, normalise=False, total_weight=1)\n\n\nkinematic_hypothesiser = ProbabilityHypothesiser(predictor=kinematic_predictor,\n                                                 updater=kinematic_updater,\n                                                 measure=Mahalanobis())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A :class:`~.HMMHypothesiser` is used for calculating categorical hypotheses.\nIt utilises the :class:`~.ObservationAccuracy` measure: a multi-dimensional extension of an\n'accuracy' score, essentially providing a measure of the similarity between two categorical\ndistributions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.hypothesiser.categorical import HMMHypothesiser\nfrom smartfusion.hypothesiser.composite import CompositeHypothesiser\n\ncategory_hypothesiser = HMMHypothesiser(predictor=category_predictor,\n                                        updater=category_updater)\nhypothesiser = CompositeHypothesiser(\n    sub_hypothesisers=[kinematic_hypothesiser, category_hypothesiser]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Associator\nWe will use a standard :class:`~.GNNWith2DAssignment` data associator.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.dataassociator.neighbour import GNNWith2DAssignment\n\ndata_associator = GNNWith2DAssignment(hypothesiser)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prior\nAs we are tracking in a composite state space, we should initiate tracks with a\n:class:`~.CompositeState` type. The kinematic sub-state of the prior is a usual Gaussian state.\nFor the categorical sub-state of the prior, equal probability is given to all 3 of the possible\nhidden classes that a target might take (the category names are also provided here).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.types.state import GaussianState, CategoricalState, CompositeState\n\nkinematic_prior = GaussianState([0, 0, 0, 0], np.diag([10, 10, 10, 10]))\ncategory_prior = CategoricalState([1 / 3, 1 / 3, 1 / 3], categories=hidden_classes)\nprior = CompositeState([kinematic_prior, category_prior])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initiator\nThe initiator is composite. For each unassociated detection, a new track will be initiated. In\nthis instance we use a :class:`~.CompositeUpdateInitiator` type. A detection has both kinematic\nand categorical information to initiate the 2 state space sub-states from. However, in an\ninstance where a detection only provides one of these, the missing sub-state for the track will\nbe initiated as the given prior's sub-state (eg. if a detection provides only kinematic\ninformation of the target, the track will initiate its categorical sub-state as the\ncategory_prior defined earlier).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.initiator.simple import SimpleMeasurementInitiator\nfrom smartfusion.initiator.categorical import SimpleCategoricalMeasurementInitiator\nfrom smartfusion.initiator.composite import CompositeUpdateInitiator\n\nkinematic_initiator = SimpleMeasurementInitiator(prior_state=kinematic_prior,\n                                                 measurement_model=None)\ncategory_initiator = SimpleCategoricalMeasurementInitiator(prior_state=category_prior,\n                                                           updater=category_updater)\ninitiator = CompositeUpdateInitiator(sub_initiators=[kinematic_initiator, category_initiator])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Deleter\nWe can use a standard :class:`~.UpdateTimeStepsDeleter`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.deleter.time import UpdateTimeStepsDeleter\n\ndeleter = UpdateTimeStepsDeleter(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tracker\nWe can use a standard :class:`~.MultiTargetTracker`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.tracker.simple import MultiTargetTracker\n\ntracker = MultiTargetTracker(initiator, deleter, all_measurements, data_associator, updater)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tracking\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tracks = set()\nfor time, ctracks in tracker:\n    tracks.update(ctracks)\n\nprint(f'Number of tracks {len(tracks)}')\nfor track in tracks:\n    print(f'id: {track.id}')\n    for state in track:\n        vector = np.round(state[0].state_vector.flatten().astype(np.double), 2)\n        print(\"%25s\" % vector, ' -- ', state[1].category, ' -- ', state.timestamp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plotting Tracks\nColour will be used to indicate a track's hidden category distribution. The `rgb` value is\ndefined by the 'bike', 'car', and 'bus' probabilities. For example, a track with high probability\nof being a 'bike' will have a high 'r' value, and hence appear more red.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for track in tracks:\n    for i, state in enumerate(track[1:], 1):\n        loc0 = track[i - 1][0].state_vector.flatten()\n        loc1 = state[0].state_vector.flatten()\n        X = [loc0[0], loc1[0]]\n        Y = [loc0[2], loc1[2]]\n        axes[2].plot(X, Y, label='track', color=list(state[1].state_vector))\n\naxes[2].set(title='Tracks', xlabel='X', ylabel='Y')\naxes[2].set_visible(True)\nset_axes_limits()\nfig"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}