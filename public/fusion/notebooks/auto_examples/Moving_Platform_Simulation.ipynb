{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Multi-Sensor Moving Platform Simulation Example\nThis example looks at how multiple sensors can be mounted on a single moving platform and exploiting a defined moving\nplatform as a sensor target.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Building a Simulated Multi-Sensor Moving Platform\nThe focus of this example is to show how to setup and configure a simulation environment in order to provide a\nmulti-sensor moving platform, as such the application of a tracker will not be covered in detail. For more information\nabout trackers and how to configure them review of the tutorials and demonstrations is recommended.\n\nThis example makes use of SMART FUSION :class:`~.MovingPlatform`, :class:`~.MultiTransitionMovingPlatform` and\n:class:`~.Sensor` objects.\n\nIn order to configure platforms, sensors and the simulation we will need to import some specific SMART FUSION objects.\nAs these have been introduced in previous tutorials they are imported upfront. New functionality within this example\nwill be imported at the relevant point in order to draw attention to the new features.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Some general imports and set up\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom matplotlib import pyplot as plt\n\nimport numpy as np\n\n# SMART FUSION imports:\nfrom smartfusion.types.state import State, GaussianState\nfrom smartfusion.types.array import StateVector\nfrom smartfusion.types.array import CovarianceMatrix\nfrom smartfusion.models.transition.linear import (\n    CombinedLinearGaussianTransitionModel, ConstantVelocity)\nfrom smartfusion.predictor.particle import ParticlePredictor\nfrom smartfusion.resampler.particle import SystematicResampler\nfrom smartfusion.updater.particle import ParticleUpdater\nfrom smartfusion.measures import Mahalanobis\nfrom smartfusion.hypothesiser.distance import DistanceHypothesiser\nfrom smartfusion.dataassociator.neighbour import GNNWith2DAssignment\nfrom smartfusion.tracker.simple import SingleTargetTracker\n\n# Define the simulation start time\nstart_time = datetime.now()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a multi-sensor platform\nWe have previously demonstrated how to create a :class:`~.FixedPlatform` which exploited a\n:class:`~.RadarRangeBearingElevation` *Sensor* in order to detect and track targets generated within a\n:class:`~.MultiTargetGroundTruthSimulator`.\n\nIn this example we are going to create a moving platform which will be mounted with a pair of sensors and moves within\na 6 dimensional state space according to the following $\\mathbf{x}$.\n\n\\begin{align}\\mathbf{x} = \\begin{bmatrix}\n                         x\\\\ \\dot{x}\\\\ y\\\\ \\dot{y}\\\\ z\\\\ \\dot{z} \\end{bmatrix}\n                     = \\begin{bmatrix}\n                         0\\\\ 0\\\\ 0\\\\ 50\\\\ 8000\\\\ 0 \\end{bmatrix}\\end{align}\n\nThe platform will be initiated with a near constant velocity model which has been parameterised to have zero noise.\nTherefore the platform location at time $k$ is given by $F_{k}x_{k-1}$ where $F_{k}$ is given by:\n\n\\begin{align}F_{k} = \\begin{bmatrix}\n           1 & \\triangle k & 0 & 0 & 0 & 0\\\\\n           0 & 1 & 0 & 0 & 0 & 0\\\\\n           0 & 0 & 1 & \\triangle k & 0 & 0\\\\\n           0 & 0 & 0 & 1 & 0 & 0\\\\\n           0 & 0 & 0 & 0 & 1 & \\triangle k \\\\\n           0 & 0 & 0 & 0 & 0 & 1\\\\\n             \\end{bmatrix}\\end{align}\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# First import the Moving platform\nfrom smartfusion.platform.base import MovingPlatform\n\n# Define the initial platform position, in this case the origin\ninitial_loc = StateVector([[0], [0], [0], [50], [8000], [0]])\ninitial_state = State(initial_loc, start_time)\n\n# Define transition model and position for 3D platform\ntransition_model = CombinedLinearGaussianTransitionModel(\n    [ConstantVelocity(0.), ConstantVelocity(0.), ConstantVelocity(0.)])\n\n# create our fixed platform\nsensor_platform = MovingPlatform(states=initial_state,\n                                 position_mapping=(0, 2, 4),\n                                 velocity_mapping=(1, 3, 5),\n                                 transition_model=transition_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With our platform generated we now need to build a set of sensors which will be mounted onto the platform. In this\ncase we will exploit a :class:`~.RadarElevationBearingRangeRate` and a :class:`~.PassiveElevationBearing` sensor\n(e.g. an optical sensor, which has no capability to directly measure range).\n\nFirst we will create a radar which is capable of measuring bearing ($\\phi$), elevation ($\\theta$), range\n($r$) and range-rate ($\\dot{r}$) of the target platform.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Import a range rate bearing elevation capable radar\nfrom smartfusion.sensor.radar.radar import RadarElevationBearingRangeRate\n\n# Create a radar sensor\nradar_noise_covar = CovarianceMatrix(np.diag(\n    np.array([np.deg2rad(3),  # Elevation\n              np.deg2rad(3),  # Bearing\n              100.,  # Range\n              25.])))  # Range Rate\n\n# radar mountings\nradar_mounting_offsets = StateVector([10, 0, 0])  # e.g. nose cone\nradar_rotation_offsets = StateVector([0, 0, 0])\n\n# Mount the radar onto the platform\n\nradar = RadarElevationBearingRangeRate(ndim_state=6,\n                                       position_mapping=(0, 2, 4),\n                                       velocity_mapping=(1, 3, 5),\n                                       noise_covar=radar_noise_covar,\n                                       mounting_offset=radar_mounting_offsets,\n                                       rotation_offset=radar_rotation_offsets,\n                                       )\nsensor_platform.add_sensor(radar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our second sensor is a passive sensor, capable of measuring the bearing ($\\phi$) and elevation ($\\theta$)\nof the target platform. For the purposes of this example we will assume that the passive sensor is an imager.\nThe imager sensor model is described by the following equations:\n\n\\begin{align}\\mathbf{z}_k = h(\\mathbf{x}_k, \\dot{\\mathbf{x}}_k)\\end{align}\n\nwhere:\n\n* $\\mathbf{z}_k$ is a measurement vector of the form:\n\n\\begin{align}\\mathbf{z}_k = \\begin{bmatrix} \\theta \\\\ \\phi \\end{bmatrix}\\end{align}\n\n* $h$ is a non - linear model function of the form:\n\n\\begin{align}h(\\mathbf{x}_k,\\dot{\\mathbf{x}}_k) = \\begin{bmatrix}\n              \\arcsin(\\mathcal{z} /\\sqrt{\\mathcal{x} ^ 2 + \\mathcal{y} ^ 2 +\\mathcal{z} ^ 2}) \\\\\n              \\arctan(\\mathcal{y},\\mathcal{x}) \\ \\\n              \\end{bmatrix} + \\dot{\\mathbf{x}}_k\\end{align}\n\n* $\\mathbf{z}_k$ is Gaussian distributed with covariance $R$, i.e.:\n\n\\begin{align}\\mathbf{z}_k  \\sim \\mathcal{N}(0, R)\\end{align}\n\n\\begin{align}R = \\begin{bmatrix}\n            \\sigma_{\\theta}^2 & 0 \\\\\n            0 & \\sigma_{\\phi}^2  \\\\\n            \\end{bmatrix}\\end{align}\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Import a passive sensor capability\nfrom smartfusion.sensor.passive import PassiveElevationBearing\n\nimager_noise_covar = CovarianceMatrix(np.diag(np.array([np.deg2rad(0.05),  # Elevation\n                                                        np.deg2rad(0.05)])))  # Bearing\n\n# imager mounting offset\nimager_mounting_offsets = StateVector([0, 8, -1])  # e.g. wing mounted imaging pod\nimager_rotation_offsets = StateVector([0, 0, 0])\n\n# Mount the imager onto the platform\nimager = PassiveElevationBearing(ndim_state=6,\n                                 mapping=(0, 2, 4),\n                                 noise_covar=imager_noise_covar,\n                                 mounting_offset=imager_mounting_offsets,\n                                 rotation_offset=imager_rotation_offsets,\n                                 )\nsensor_platform.add_sensor(imager)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice that we have added sensors to specific locations on the aircraft, defined by the mounting_offset parameter.\nThe values in this array are defined in the platforms local coordinate frame of reference. So in this case an offset\nof $[0, 8, -1]$ means the sensor is located 8 meters to the right and 1 meter below the center point of the\nplatform.\n\nNow that we have mounted the two sensors we can see that the platform object has both associated with it:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sensor_platform.sensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a Target Platform\nThere are two ways of generating a target in SMART FUSION. Firstly, we can use the inbuilt ground-truth generator\nfunctionality within SMART FUSION, which we demonstrated in the previous example, and creates a random target based on\nour selected parameters. The second method provides a means to generate a target which will perform specific\nbehaviours, this is the approach we will take here.\n\nIn order to create a target which moves in pre-defined sequences we exploit the fact that platforms can be used as\nsensor targets within a simulation, coupled with the :class:`~.MultiTransitionMovingPlatform` which enables a platform\nto be provided with a pre-defined list of transition models and transition times. The platform will continue to loop\nover the transition sequence provided until the simulation ends.\n\nWhen simulating sensor platforms it is important to note that within the simulation SMART FUSION treats all platforms as\npotential targets. Therefore if we created multiple sensor platforms they would each *sense* all other platforms\nwithin the simulation (sensor-target geometry dependant).\n\nFor this example we will create an air target which will fly a sequence of straight and level followed by a\ncoordinated turn in the $x-y$ plane. This is configured such that the target will perform each manoeuvre for 8\nseconds, and it will turn through 45 degrees over the course of the turn manoeuvre.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Import a Constant Turn model to enable target to perform basic manoeuvre\nfrom smartfusion.models.transition.linear import KnownTurnRate\n\nstraight_level = CombinedLinearGaussianTransitionModel(\n    [ConstantVelocity(0.), ConstantVelocity(0.), ConstantVelocity(0.)])\n\n# Configure the aircraft turn behaviour\nturn_noise_diff_coeffs = np.array([0., 0.])\n\nturn_rate = np.pi/32  # specified in radians per seconds...\n\nturn_model = KnownTurnRate(turn_noise_diff_coeffs=turn_noise_diff_coeffs, turn_rate=turn_rate)\n\n# Configure turn model to maintain current altitude\nturning = CombinedLinearGaussianTransitionModel(\n    [turn_model, ConstantVelocity(0.)])\n\nmanoeuvre_list = [straight_level, turning]\nmanoeuvre_times = [timedelta(seconds=8),\n                   timedelta(seconds=8)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have created a list of manoeuvre behaviours and durations we can build our multi-transition moving\nplatform. Because we intend for this platform to be a target we do not need to attach any sensors to it.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Import a multi-transition moving platform\nfrom smartfusion.platform.base import MultiTransitionMovingPlatform\n\ninitial_target_location = StateVector([[0], [-40], [1800], [0], [8000], [0]])\ninitial_target_state = State(initial_target_location, start_time)\ntarget = MultiTransitionMovingPlatform(transition_models=manoeuvre_list,\n                                       transition_times=manoeuvre_times,\n                                       states=initial_target_state,\n                                       position_mapping=(0, 2, 4),\n                                       velocity_mapping=(1, 3, 5),\n                                       sensors=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating the simulator\nNow that we have build our sensor platform and a target platform we need to wrap them in a simulator. Because we do\nnot want any additional ground truth objects, which is how most simulators work in SMART FUSION, we need to use a\n:class:`~.DummyGroundTruthSimulator` which returns a set of empty ground truth paths with timestamps. These are then\nfeed into a :class:`~.PlatformDetectionSimulator` with the two platforms we have already built.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Import the required simulators\nfrom smartfusion.simulator.simple import DummyGroundTruthSimulator\nfrom smartfusion.simulator.platform import PlatformDetectionSimulator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now need to create an array of timestamps which starts at *datetime.now()* and enable the simulator to run for\n25 seconds.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "times = np.arange(0, 24, 1)  # 25 seconds\n\ntimestamps = [start_time + timedelta(seconds=float(elapsed_time)) for elapsed_time in times]\n\ntruths = DummyGroundTruthSimulator(times=timestamps)\nsim = PlatformDetectionSimulator(groundtruth=truths, platforms=[sensor_platform, target])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a Tracker\nNow that we have setup our sensor platform, target and simulation we need to create a tracker. For this example we\nwill use a Particle Filter as this enables us to handle the non-linear nature of the imaging sensor. In this example\nwe will use an inflated constant noise model to account for target motion uncertainty.\n\nNote that we don't add a measurement model to the updater, this is because each sensor adds their measurement model to\neach detection they generate. The tracker handles this internally by checking for a measurement model with each\ndetection it receives and applying only the relevant measurement model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "target_transition_model = CombinedLinearGaussianTransitionModel(\n    [ConstantVelocity(5), ConstantVelocity(5), ConstantVelocity(1)])\n\n# First add a Particle Predictor\npredictor = ParticlePredictor(target_transition_model)\n\n# Now create a resampler and particle updater\nresampler = SystematicResampler()\nupdater = ParticleUpdater(measurement_model=None,\n                          resampler=resampler)\n\n# Create a particle initiator\nfrom smartfusion.initiator.simple import GaussianParticleInitiator, SinglePointInitiator\nsingle_point_initiator = SinglePointInitiator(\n    GaussianState([[0], [-40], [2000], [0], [8000], [0]], np.diag([10000, 1000, 10000, 1000, 10000, 1000])),\n    None)\n\ninitiator = GaussianParticleInitiator(number_particles=500,\n                                      initiator=single_point_initiator)\n\nhypothesiser = DistanceHypothesiser(predictor, updater, measure=Mahalanobis(), missed_distance=np.inf)\ndata_associator = GNNWith2DAssignment(hypothesiser)\n\nfrom smartfusion.deleter.time import UpdateTimeStepsDeleter\ndeleter = UpdateTimeStepsDeleter(time_steps_since_update=10)\n\n# Create a Kalman single-target tracker\ntracker = SingleTargetTracker(\n    initiator=initiator,\n    deleter=deleter,\n    detector=sim,\n    data_associator=data_associator,\n    updater=updater\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The final step is to iterate our tracker over the simulation and plot out the results. Because we have a bearing\nonly sensor it does not make sense to plot out the detections without animating the resulting plot. This\nanimation shows the sensor platform (blue) moving towards the true target position (red). The estimated target\nposition is shown in black, radar detections are shown in yellow while the bearing only imager detections are\ncoloured green.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from matplotlib import animation\nimport matplotlib\n\nmatplotlib.rcParams['animation.html'] = 'jshtml'\n\nfrom smartfusion.models.measurement.nonlinear import CartesianToElevationBearingRangeRate\nfrom smartfusion.functions import sphere2cart\n\nfig = plt.figure(figsize=(10, 6))\nax = fig.add_subplot(1, 1, 1)\n\n\nframes = []\nfor time, ctracks in tracker:\n    artists = []\n\n    ax.set_xlabel(\"$East$\")\n    ax.set_ylabel(\"$North$\")\n    ax.set_ylim(0, 2250)\n    ax.set_xlim(-1000, 1000)\n    X = [state.state_vector[0] for state in sensor_platform]\n    Y = [state.state_vector[2] for state in sensor_platform]\n    artists.extend(ax.plot(X, Y, color='b'))\n\n    for detection in sim.detections:\n        if isinstance(detection.measurement_model, CartesianToElevationBearingRangeRate):\n            x, y = detection.measurement_model.inverse_function(detection)[[0, 2]]\n            color = 'y'\n        else:\n            r = 10000000\n            # extract the platform rotation offsets\n            _, el_offset, az_offset = sensor_platform.orientation\n            # obtain measurement angles and map to cartesian\n            e, a = detection.state_vector\n            x, y, _ = sphere2cart(r, a + az_offset, e + el_offset)\n            x += detection.measurement_model.translation_offset[0]\n            y += detection.measurement_model.translation_offset[1]\n            color = 'g'\n        X = [sensor_platform.state_vector[0], x]\n        Y = [sensor_platform.state_vector[2], y]\n        artists.extend(ax.plot(X, Y, color=color))\n\n    X = [state.state_vector[0] for state in target]\n    Y = [state.state_vector[2] for state in target]\n    artists.extend(ax.plot(X, Y, color='r'))\n\n    for track in ctracks:\n        X = [state.mean[0] for state in track]\n        Y = [state.mean[2] for state in track]\n        artists.extend(ax.plot(X, Y, color='k'))\n\n    frames.append(artists)\n\nanimation.ArtistAnimation(fig, frames)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To increase your confidence with simulated platform targets it would be good practice to modify the target to fly\npre-defined shapes, a race track oval for example. You could also experiment with different sensor performance levels\nin order to see at what point the tracker is no longer able to generate a reasonable estimate of the target location.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key points\n1. Platforms, static or moving, can be used as targets for sensor platforms.\n2. Simulations can be built with only known platform behaviours when you want to test specific scenarios.\n3. A tracker can be configured to exploit all sensor data created in a simulation.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}