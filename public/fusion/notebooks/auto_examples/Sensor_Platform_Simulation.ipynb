{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Sensor Platform Simulation Example\nThis example looks at how platforms and sensors can be used within the SMART FUSION simulation capability.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Building a Simulated Sensor Platform\nThe focus of this example is to show how to setup and configure simulations, as such the application of a tracker\nwill not be covered in detail. For more information about trackers and how to configure them review of the\ntutorials and demonstrations is recommended.\n\nThis example makes use of SMART FUSION :class:`~.FixedPlatform` and :class:`~.Sensor` objects.\n\nIn order to configure platforms, sensors and the simulation we will need to import some specific SMART FUSION objects.\nAs these have been introduced in previous tutorials they are imported upfront. New functionality within this example\nwill be imported at the relevant point in order to draw attention to the new features.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Some general imports and set up\nfrom datetime import datetime\nfrom datetime import timedelta\n\nimport numpy as np\n\n# SMART FUSION imports:\nfrom smartfusion.types.state import State, GaussianState\nfrom smartfusion.types.array import StateVector, CovarianceMatrix\nfrom smartfusion.models.transition.linear import (\n    CombinedLinearGaussianTransitionModel, ConstantVelocity)\nfrom smartfusion.models.measurement.nonlinear import CartesianToElevationBearingRange\nfrom smartfusion.updater.kalman import UnscentedKalmanUpdater\nfrom smartfusion.predictor.kalman import UnscentedKalmanPredictor\nfrom smartfusion.deleter.time import UpdateTimeStepsDeleter\nfrom smartfusion.tracker.simple import MultiTargetTracker\nfrom matplotlib import pyplot as plt\n\n# Define the simulation start time\nstart_time = datetime.now()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a Platform\nThe first element we need to create is a platform. For this first example we will build a static (or *fixed*) platform\nwhich is located at the origin. For this example we are going to work in a 6-dimensional state space our platform will\nhave the following $\\mathbf{x}$.\n\n\\begin{align}\\mathbf{x} = \\begin{bmatrix}\n                         x\\\\ \\dot{x}\\\\ y\\\\ \\dot{y}\\\\ z\\\\ \\dot{z} \\end{bmatrix}\n                     = \\begin{bmatrix}\n                         0\\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ 0 \\end{bmatrix}\\end{align}\n\nBecause the platform is static we only need to define $(x, y, z)$, any internal interaction with the platform\nwhich requires knowledge of platform velocity $(\\dot{x}, \\dot{y}, \\dot{z})$ will be returned $(0, 0, 0)$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# First import the fixed platform\nfrom smartfusion.platform.base import FixedPlatform\n\n# Define the initial platform position, in this case the origin\nplatform_state_vector = StateVector([[0], [0], [0]])\nposition_mapping = (0, 1, 2)\n\n# Create the initial state (position, time), notice it is set to the simulation start time defined earlier\nplatform_state = State(platform_state_vector, start_time)\n\n# create our fixed platform\nplatform = FixedPlatform(states=platform_state,\n                         position_mapping=position_mapping)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have now created a platform within SMART FUSION and located it at the origin of our state space. As previously stated\nthe platform will have a velocity $(\\dot{x}, \\dot{y}, \\dot{z})$ of $(0, 0, 0)$ which we can check:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "platform.velocity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also query the platform orientation:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "platform.orientation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a Sensor\nNow that we have a platform the next step is to create a sensor which can be added to the platform. In this example a\nRadar will be created which is capable of measuring the range, bearing and elevation of the target relative to the\nsensor.\n\nThe :class:`~.RadarRangeBearingElevation`  provides a sensor wrapper around the\n:class:`~.CartesianToElevationBearingRange` measurement model. The measurement model provides a time-invariant\nmeasurement model, where measurements are assumed to be received in the form of elevation ($\\theta$),\nbearing ($\\phi$) and range ($r$) with Gaussian noise in each dimension.\n\nThe model is described by the following equations:\n\n\\begin{align}\\mathbf{z}_k = h(\\mathbf{x}_k, \\dot{\\mathbf{x}}_k)\\end{align}\n\nwhere $\\mathbf{z}_k$ is a measurement vector of the form:\n\n\\begin{align}\\mathbf{z}_k = \\begin{bmatrix} \\theta \\\\ \\phi \\\\ r \\end{bmatrix}\\end{align}\n\nand $h$ is a non-linear model function of the form:\n\n\\begin{align}h(\\mathbf{x}_k,\\dot{\\mathbf{x}}_k) = \\begin{bmatrix}\n                    \\arcsin{(\\mathcal{z}/\\sqrt{\\mathcal{x}^2 + \\mathcal{y}^2 +\\mathcal{z}^2})} \\\\\n                    \\arctan{(\\mathcal{y},\\mathcal{x})} \\\\\n                    \\sqrt{\\mathcal{x}^2 + \\mathcal{y}^2 + \\mathcal{z}^2}\n                    \\end{bmatrix} + \\dot{\\mathbf{x}}_k\\end{align}\n\nand finally $\\mathbf{z}_k$ is Gaussian distributed with covariance $R$, i.e.:\n\n\\begin{align}\\mathbf{z}_k \\sim \\mathcal{N}(0,R)\\end{align}\n\n\\begin{align}R = \\begin{bmatrix}\n            \\sigma_{\\theta}^2 & 0 & 0 \\\\\n            0 & \\sigma_{\\phi}^2 & 0 \\\\\n            0 & 0 & \\sigma_{r}^2\n            \\end{bmatrix}\\end{align}\n\nWe now create our radar.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Import a radar sensor model\nfrom smartfusion.sensor.radar.radar import RadarElevationBearingRange\n\n# First we need to configure a radar\n\n# Generate a radar sensor with a suitable measurement accuracy\nnoise_covar = CovarianceMatrix(np.array(np.diag([np.deg2rad(3)**2,\n                                                 np.deg2rad(0.15)**2,\n                                                 25**2])))\n# this radar measures range with an accuracy of +/- 25m, and elevation accuracy +/- 3\n# degrees and bearing accuracy of +/- 0.15 degrees\n\n# The radar needs to be informed of where x, y, and z are in the target state space\nradar_mapping = (0, 2, 4)\n\n# Instantiate the radar\nradar = RadarElevationBearingRange(ndim_state=6,\n                                   position_mapping=radar_mapping,\n                                   noise_covar=noise_covar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Attach the sensor to the platform\nNow that we have created our radar sensor we need to mount the sensor onto the platform we have previously created.\n\nSensors can be mounted with two additional parameters; the mounting offset and rotation offset.\n\nThe mounting offset:\n\n * defines how the sensors position is offset from the platform,\n * defaults to a position offset of zero.\n\nThe rotation_offset:\n\n * defines the sensors orientation relative to that of the platform,\n * defaults to a zero orientation offset.\n\nThe default assumption is that the sensor is located at the centre point of the platform and orientated to align with\nthe platform body. In this example we are happy to use the default assumptions and therefore the sensor can be added.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "platform.add_sensor(radar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As before we can query the platform to demonstrate that it has a sensor mounted:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "platform.sensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You will notice that platform.sensors returns a list which contains our single sensor. This hints at the multi-sensor\nplatform functionality which is shown in a subsequent example.\n\nWe can also check to ensure that the default mounting_offsets have been applied:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "radar.mounting_offset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And that the rotation_offsets have been applied:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "radar.rotation_offset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Building a simulation\nNow that we have created a sensor platform we need to build a simulation which generates targets for the sensor to\ndetect and track. For this example we are going to use a :class:`~.MultiTargetGroundTruthSimulator`. this simulator\nenables multiple ground truth targets to be created based on a number of user defined parameters.\n\nIn this example targets are initiated with values based upon a mean state and a covariance, using a Gaussian\nassumption. This is done by creating a :class:`~.GaussianState` object which describes the distribution from which we\nwant our targets to be drawn from. For this example targets will be generated using the following parameters:\n\n * $x$ is Gaussian distributed around the platform location with variance of $\\mathrm{2}km$\n * $y$ is Gaussian distributed around the platform location with variance of $\\mathrm{2}km$\n * $z$ is Gaussian distributed around an altitude of $\\mathrm{9}km$ with variance of $\\mathrm{0.1}km$\n * $\\dot{x}$ is Gaussian distributed around $\\mathrm{100}ms^{-1}$ with variance of $\\mathrm{50}ms^{-1}$\n * $\\dot{y}$ is Gaussian distributed around $\\mathrm{100}ms^{-1}$ with variance of $\\mathrm{50}ms^{-1}$\n * $\\dot{z}$ is Gaussian distributed around $\\mathrm{0}ms^{-1}$ with variance of $\\mathrm{1}ms^{-1}$\n\nWe will also configure our simulator to randomly create and delete targets, based on a birth rate and death rate we\nspecify. In this example we set the birth rate to be 0.10, i.e. on any given time step there is a 10% chance of a new\ntarget being initiated. We have set the death rate to 0.01, i.e. on any given time step there is a 1% chance that a\ntarget will be removed from the simulation.\n\nThe above setup will provide a case which loosely approximates an air surveillance radar at an airport.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.simulator.simple import MultiTargetGroundTruthSimulator\n\n# Set a constant velocity transition model for the targets\ntransition_model = CombinedLinearGaussianTransitionModel(\n    [ConstantVelocity(0.5), ConstantVelocity(0.5), ConstantVelocity(0.1)])\n\n# Define the Gaussian State from which new targets are sampled on initialisation\ninitial_target_state = GaussianState(StateVector([[0], [0], [0], [0], [9000], [0]]),\n                                     CovarianceMatrix(np.diag([2000, 50, 2000, 50, 100, 1])))\n\ngroundtruth_sim = MultiTargetGroundTruthSimulator(\n    transition_model=transition_model,  # target transition model\n    initial_state=initial_target_state,  # add our initial state for targets\n    timestep=timedelta(seconds=1),  # time between measurements\n    number_steps=120,  # 2 minute\n    birth_rate=0.10,  # 10% chance of a new target being born\n    death_probability=0.01  # 1% chance of a target being killed\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have set up our ground truth simulation we need to add our platform into the simulation capability. This\nis done using the :class:`~.PlatformDetectionSimulator`. This simulator allows a *list* of platforms to be added into\nthe simulation, when the simulation is processed the platforms are able to make detections of both the ground truth\ntargets and other platforms.\n\nIn this case we have a single platform, therefore the radar sensor on this platform will only be able to make\nmeasurements of the ground truth objects generated by the simulator.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Import the PlatformDetectionSimulator\nfrom smartfusion.simulator.platform import PlatformDetectionSimulator\n\nsim = PlatformDetectionSimulator(groundtruth=groundtruth_sim, platforms=[platform])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating the Tracker Components\nAs stated above the aim of this example is to show how :class:`~.Platform`, :class:`~.Sensor` and\n:class:`~.Simulator` work within SMART FUSION. We will therefore quickly build an Unscented Kalman Filter which\ninitiates measurements using a simple heuristic initiation and deletes any track where no detection is associated for\n2 consecutive time steps. There are a number of tutorials for how to build the tracking components provided in the\n`auto_tutorials/index:Tutorials`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Create an Unscented Kalman Predictor\npredictor = UnscentedKalmanPredictor(transition_model)\n\n# Create an Unscented Kalman Updater, note our sensor adds a measurement model to detections\nupdater = UnscentedKalmanUpdater(measurement_model=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When we build our updater you will notice that we do not provide a measurement model. This is because we\nhave defined a measurement model which is attached to our radar sensor, each detection made by this sensor\nwill have our radar measurement model associated with it. In SMART FUSION the :class:`~.Updater` checks the\ndetections provided and will use any measurement model attached to the detection.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup Initiator class for the Tracker\nWe will now build a simple heuristic initiator.\nThis assumes most of the deviation is caused by the bearing measurement error. It converts the bearing error error\ninto $x, y$ components using the target bearing. For z, we simply use $r*\\sigma_{\\theta}^2$ (this ignores\nany bearing or range related components). Velocity covariances are just based on expected velocity range of targets.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.types.state import GaussianState\nfrom smartfusion.types.update import GaussianStateUpdate\nfrom smartfusion.initiator.simple import SimpleMeasurementInitiator\nfrom smartfusion.types.track import Track\nfrom smartfusion.types.hypothesis import SingleHypothesis\n\n\nclass Initiator(SimpleMeasurementInitiator):\n    def initiate(self, detections, timestamp, **kwargs):\n        MAX_DEV = 500.\n        tracks = set()\n        measurement_model = self.measurement_model\n        for detection in detections:\n            state_vector = measurement_model.inverse_function(\n                            detection)\n            model_covar = measurement_model.covar()\n\n            el_az_range = np.sqrt(np.diag(model_covar))  # elev, az, range\n\n            std_pos = detection.state_vector[2, 0]*el_az_range[1]\n            stdx = np.abs(std_pos*np.sin(el_az_range[1]))\n            stdy = np.abs(std_pos*np.cos(el_az_range[1]))\n            stdz = np.abs(detection.state_vector[2, 0]*el_az_range[0])\n            if stdx > MAX_DEV:\n                print('Warning - X Deviation exceeds limit!!')\n            if stdy > MAX_DEV:\n                print('Warning - Y Deviation exceeds limit!!')\n            if stdz > MAX_DEV:\n                print('Warning - Z Deviation exceeds limit!!')\n            C0 = np.diag(np.array([stdx, 50.0, stdy, 50.0, stdz, 10.0])**2)\n\n            tracks.add(Track([GaussianStateUpdate(\n                state_vector,\n                C0,\n                SingleHypothesis(None, detection),\n                timestamp=detection.timestamp)\n            ]))\n        return tracks\n\n\nmeas_model = CartesianToElevationBearingRange(\n            ndim_state=6,\n            mapping=np.array([0, 2, 4]),\n            noise_covar=noise_covar)\n\nprior_state = GaussianState(\n        np.array([[0], [0], [0], [0], [0], [0]]),\n        np.diag([1000, 50, 1000, 50, 1000, 10.0])**2)\n\ninitiator = Initiator(prior_state, measurement_model=meas_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have setup out tracking scenario we can wrap our simulation environment within a\n:class:`~.MultiTargetTracker`. This takes our tracker configurations and the simulation we previously created and\nbrings them together into a single iterable object.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.hypothesiser.distance import DistanceHypothesiser\nfrom smartfusion.measures import Mahalanobis\nhypothesiser = DistanceHypothesiser(predictor, updater, measure=Mahalanobis(), missed_distance=3)\n\nfrom smartfusion.dataassociator.neighbour import NearestNeighbour\ndata_associator = NearestNeighbour(hypothesiser)\n\ndeleter = UpdateTimeStepsDeleter(time_steps_since_update=2)\n\n# Create a Kalman multi-target tracker\nkalman_tracker = MultiTargetTracker(\n    initiator=initiator,\n    deleter=deleter,\n    detector=sim,\n    data_associator=data_associator,\n    updater=updater\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The final step is to iterate our tracker over the simulation:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "kalman_tracks = {}  # Store for plotting later\ngroundtruth_paths = {}  # Store for plotting later\ndetections = []  # Store for plotting later\n\nfor time, ctracks in kalman_tracker:\n    for track in ctracks:\n        loc = (track.state_vector[0], track.state_vector[2])\n        if track not in kalman_tracks:\n            kalman_tracks[track] = []\n        kalman_tracks[track].append(loc)\n\n    for truth in groundtruth_sim.current[1]:\n        loc = (truth.state_vector[0], truth.state_vector[2])\n        if truth not in groundtruth_paths:\n            groundtruth_paths[truth] = []\n        groundtruth_paths[truth].append(loc)\n\n    for detection in sim.detections:\n        detect_state = detection.measurement_model.inverse_function(detection)\n        loc = (detect_state[0], detect_state[2])\n        detections.append(loc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting the outputs\nFirst we will plot the ground truth paths (red) which have been generated in the simulation step.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10, 6))\nax = fig.add_subplot(1, 1, 1)\nax.set_xlabel(\"$East$\")\nax.set_ylabel(\"$North$\")\nax.set_ylim(-10000, 10000)\nax.set_xlim(-10000, 10000)\n\nfor key in groundtruth_paths:\n    X = [coord[0] for coord in groundtruth_paths[key]]\n    Y = [coord[1] for coord in groundtruth_paths[key]]\n    ax.plot(X, Y, color='r')  # Plot true locations in red\n\n# plot platform location\nax.scatter(0, 0, color='y')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we now overlay the detections (black) onto the ground truth paths (red) we can see how the sensor performs,\ngenerating detections based upon the :class:`~.MeasurementModel` we provided it with. The platform location is\nshown in yellow.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10, 6))\nax = fig.add_subplot(1, 1, 1)\nax.set_xlabel(\"$East$\")\nax.set_ylabel(\"$North$\")\nax.set_ylim(-10000, 10000)\nax.set_xlim(-10000, 10000)\n\nfor key in groundtruth_paths:\n    X = [coord[0] for coord in groundtruth_paths[key]]\n    Y = [coord[1] for coord in groundtruth_paths[key]]\n    ax.plot(X, Y, color='r')  # Plot true locations in red\n\nX = [coord[0] for coord in detections]\nY = [coord[1] for coord in detections]\nax.scatter(X, Y, color='k')  # Plot detections in black\n\n# plot platform location\nax.scatter(0, 0, color='y')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we overlay the ground truth locations (red), detections (black) and tracks (blue). This shows all the stages of\nthe tracker simulation we have built in a single figure. The platform location is shown in yellow.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10, 6))\nax = fig.add_subplot(1, 1, 1)\nax.set_xlabel(\"$East$\")\nax.set_ylabel(\"$North$\")\nax.set_ylim(-10000, 10000)\nax.set_xlim(-10000, 10000)\nfor key in groundtruth_paths:\n    X = [coord[0] for coord in groundtruth_paths[key]]\n    Y = [coord[1] for coord in groundtruth_paths[key]]\n    ax.plot(X, Y, color='r')  # Plot true locations in red\n\nfor key in kalman_tracks:\n    X = [coord[0] for coord in kalman_tracks[key]]\n    Y = [coord[1] for coord in kalman_tracks[key]]\n    ax.plot(X, Y, color='b')  # Plot track estimates in blue\n\nX = [coord[0] for coord in detections]\nY = [coord[1] for coord in detections]\nax.scatter(X, Y, color='k')  # Plot detections in black\n\n# plot platform location\nax.scatter(0, 0, color='y')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we can plot the estimated tracks (blue) alongside the ground truth paths (red). Because we used a noisy\nsensor this view makes it easier to quickly see the tracker performance. The platform location is\nshown in yellow.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10, 6))\nax = fig.add_subplot(1, 1, 1)\nax.set_xlabel(\"$East$\")\nax.set_ylabel(\"$North$\")\nax.set_ylim(-10000, 10000)\nax.set_xlim(-10000, 10000)\nfor key in groundtruth_paths:\n    X = [coord[0] for coord in groundtruth_paths[key]]\n    Y = [coord[1] for coord in groundtruth_paths[key]]\n    ax.plot(X, Y, color='r')  # Plot true locations in red\n\nfor key in kalman_tracks:\n    X = [coord[0] for coord in kalman_tracks[key]]\n    Y = [coord[1] for coord in kalman_tracks[key]]\n    ax.plot(X, Y, color='b')  # Plot track estimates in blue\n\n# plot platform location\nax.scatter(0, 0, color='y')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To familiarise yourself with sensors it is recommended that you investigate changing the parameters within the sensor\nMeasurement Model in order to see the impact on detections and ultimately tracker performance. For this example we\nused a *hard* association logic coupled with a relatively noisy sensor. A suggested further exercise is to modify this\nexample to use a *soft* association step such as Probabilistic Data Association (:class:`~.PDA`) or\nJoint Probabilistic Data Association (:class:`~.JPDA`).\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key points\n1. Sensor platforms, which combine :class:`~.Sensor` and :class:`~.Platform` can be created in SMART FUSION and used\n   as part of a tracking simulation.\n2. When using a :class:`~.Sensor` to generate detections there is no need to provide an :class:`~.Updater` with a\n   :class:`~.MeasurementModel` as each detection is attributed with the relevant sensors measurement model.\n3. Sensors will generate detections of all platforms within the simulation, not just ground truth objects.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}