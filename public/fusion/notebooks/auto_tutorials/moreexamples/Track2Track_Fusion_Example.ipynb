{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Multi-Sensor Fusion: Covariance Intersection Using Tracks as Measurements\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Background\nThe Covariance Intersection Algorithm from Julier and Uhlmann [#]_ is a popular algorithm for\ntrack-to-track fusion in target tracking systems. This approach is highly appealing due to its\nrobustness, simple structure, and applicability to any tracking system that uses Gaussians as the\nbasis for tracking. Generalisations to non-Gaussian systems have been proposed based on the\nexponential mixture density structure of the algorithm. The approach is based on a simple rule\ncalled the Chernoff Fusion Rule. However, due to the non-Bayesian formulation of the rule, it\ncannot be integrated straightforwardly into multi-target tracking algorithms which are based on\nBayesian formulations.\n\nA new Bayesian formulation for covariance intersection was recently proposed which allows for the\nintegration of the approach into multi-target tracking algorithms. [#]_ The new formulation\nrecasts the fusion rule as a Bayesian update rule that calculates a normalisation constant which\nenables integration into different multi-target tracking algorithms.\n\nIn this example we demonstrate the approach with different multi-target trackers in a\nmulti-platform scenario where the sensors output estimated target tracks instead of raw\nmeasurements. In real life situations, such sensors make multi-target tracking more accessible to\nnew researchers because the researchers don't have to know about or implement target filtering\nand/or tracking algorithms on their own. However, when there are multiple sensors measuring the\nsame target space and they all produce estimated tracks, as demonstrated in this example, it is\nnot immediately clear how to combine this information into a single set of tracks. This is where\ncovariance intersection comes in.\n\nThe concept of covariance intersection relies on the aforementioned Chernoff fusion rule [#]_ :\n\n\\begin{align}p_{\\omega}(x_{k}) = \\frac{p_{1}(x_{k})^{\\omega}p_{2}(x_{k})^{1-\\omega}}{\\int p_{1}(x)^{\\omega}p_{2}(x)^{1-\\omega}dx}\\end{align}\n\n\nIn situations where $p_1(x)$ and $p_2(x)$ are multivariate Gaussian distributions,\nthis formula is equal to the Covariance Intersection Algorithm from Julier and Uhlmann. In the\nCovariance Intersection Algorithm, the weighting parameter, $\\omega \\in [0, 1]$ is chosen\nusing an optimization algorithm. In this example, we have set it to $0.5$ for simplicity.\n\nWe also introduce the following identity. Given two Gaussians, $N(x ; a, A)$ and\n$N(x ; b, B)$ with the same dimension, we have:\n\n\\begin{align}\\left({\\frac{\\mathcal{N}(x ; a, A)}{\\mathcal{N}(x ; a, A)}}\\right)^\\omega \\mathcal{N}(x ; b,  B) \\propto \\mathcal{N}(a ; b,  V) \\mathcal{N}(x ; d,  D)\\end{align}\n\n\nwhere\n\n\\begin{align}D &= \\left(\\omega A^{-1}+(1-\\omega) B^{-1}\\right)^{-1} \\\\\n          d &= D\\left(\\omega A^{-1} {a}+(1-\\omega ) B^{-1} {b}\\right) \\\\\n          V &= A/(1-\\omega )+ B/\\omega\\end{align}\n\n\nThis example considers the Gaussian mixture probability hypothesis density (GM-PHD) algorithm\nas the tracker for the track-to-track fusion. The following table shows the formulas used in the\nregular GM-PHD, and the GM-PHD covariance intersector algorithm.\n\n<img src=\"https://smartfusion.rtfd.io/en/latest/_static/covariance_intersection_formulas.png\" width=\"700\" alt=\"Formulas for the posterior/fused intensity, gaussian components, updated weight, updated\">\n        mean, updated covariance, innovation, Kalman gain, and innovation covariance in the\n        GM-PHD and the GM-PHD Covariance Intersector algorithm.\n\n\nThe specifics for implementing the Covariance Intersection Algorithm in several popular\nmulti-target tracking algorithms was expanded upon recently by Clark et al [#]_. The work\nincludes a discussion of SMART FUSION and and is used as the basis for this example.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The rest of this example will continue as follows:\n  * Create a simulator for the ground truth\n  * Create 2 radar simulators, one on the ground and one that is airborne\n  * Make a JPDA tracker for the first radar, and a Gaussian mixture linear complexity with\n    cumulants (GM-LCC) tracker for the second. These will mimic the situation where the radar\n    sensors outputs tracks instead of raw measurements.\n  * Create a GM-PHD tracker that will perform measurement fusion, using all measurements from\n    both radars. This is created to compare with the covariance intersection method.\n  * Create a GM-PHD tracker that will perform track fusion via covariance intersection using\n    the :class:`ChernoffUpdater` class.\n  * Create metric managers for each of the four trackers\n  * Set up the detection feeders. Each tracker will receive measurements using a custom\n    :class:`DummyDetector` class. The track fusion tracker will also use the\n    :class:`Tracks2GaussianDetectionFeeder` class.\n  * Run the simulation\n  * Plot the resulting tracks and the metrics over time\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy\nimport numpy as np\nfrom datetime import datetime\n\nstart_time = datetime.now()\nnum_steps = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1: Create a Ground Truth Simulator\nWe will simulate the paths of two targets using the :class:`~.MultiTargetGroundTruthSimulator`.\nWe can dictate the starting states of the two targets using the `preexisting_states` parameter.\nThe targets start at [-100, -200, 500] and [0, 300, 500] respectively. Their initial velocities\nare [4, 0.5, 0] and [5, -0.5, 0] and they move according to a constant velocity transition model\nwith noise.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.models.transition.linear import CombinedLinearGaussianTransitionModel,\\\n                                               ConstantVelocity\ntruth_transition_model = CombinedLinearGaussianTransitionModel(\n    (ConstantVelocity(0.5), ConstantVelocity(0.5), ConstantVelocity(0.5)))\n\nfrom smartfusion.simulator.simple import MultiTargetGroundTruthSimulator\nfrom smartfusion.types.state import GaussianState\ngt_simulator = MultiTargetGroundTruthSimulator(\n    transition_model=truth_transition_model,\n    initial_state=GaussianState([0, 0, 0, 0, 500, 0], np.diag([100, 1, 100, 1, 100, 1]),\n                                timestamp=start_time),\n    birth_rate=0,\n    death_probability=0,\n    number_steps=num_steps,\n    preexisting_states=[[-100, 4, -200, 0.5, 500, 0], [0, 5, 300, -0.5, 500, 0]]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2: Create Two Radars and a Detection Simulation\nThe two radars can share the same clutter model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.models.clutter.clutter import ClutterModel\nclutter_model = ClutterModel(\n    clutter_rate=2.0,\n    distribution=np.random.default_rng().uniform,\n    dist_params=((-600.0, 600.0), (-600.0, 600.0), (250.0, 750.0))\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first radar will be airborne, at an altitude of approximately 3000 m. It makes detections\nwith an elevation, bearing, and range measurement model. By setting the `max_range` to 3500, we\ncan ensure that it does not make detections of the other radar (which will be far away on the\nground). We will later do a similar thing with the second radar. This mimics a real-life scenario\nwhere each radar is outside the field-of-view of the other.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.sensor.radar.radar import RadarElevationBearingRange\nfrom smartfusion.types.array import CovarianceMatrix\nfrom smartfusion.types.array import StateVector\nfrom smartfusion.platform.base import MovingPlatform\nfrom smartfusion.types.state import State\n\nradar1 = RadarElevationBearingRange(\n    ndim_state=6,\n    position_mapping=(0, 2, 4),\n    noise_covar=CovarianceMatrix(np.diag([np.deg2rad(0.005), np.deg2rad(0.005), 0.05])),\n    mounting_offset=StateVector([10, 0, 0]),\n    clutter_model=clutter_model,\n    max_range=3500\n)\n\n# Mount the radar onto a moving platform. The platform starts at [-250, 50, 3000]\n# with velocity [1, 5, 0] and moves according to a constant velocity model with low noise\nsensor1_initial_loc = StateVector([[-250], [1], [50], [5], [3000], [0]])\ninitial_state = State(sensor1_initial_loc, start_time)\nsensor1_transition_model = CombinedLinearGaussianTransitionModel(\n    [ConstantVelocity(0.3), ConstantVelocity(0.3), ConstantVelocity(0.3)])\nsensor1_platform = MovingPlatform(\n    states=initial_state,\n    position_mapping=(0, 2, 4),\n    velocity_mapping=(1, 3, 5),\n    transition_model=sensor1_transition_model,\n    sensors=[radar1]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The second radar will be stationary on the ground at the point [2000, 50, 0]. This radar also\nmeasures in 3D using bearing, range, and elevation.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "radar2_noise_covar = CovarianceMatrix(np.diag([np.deg2rad(0.005), np.deg2rad(0.005), 0.05]))\nradar2 = RadarElevationBearingRange(\n    ndim_state=6,\n    position_mapping=(0, 2, 4),\n    noise_covar=radar2_noise_covar,\n    clutter_model=clutter_model,\n    max_range=3000\n)\n\n# Make a platform and mount the radar\nfrom smartfusion.platform.base import FixedPlatform\nsensor2_platform = FixedPlatform(\n    State([2000, 0, 50, 0, 0, 0]),\n    position_mapping=[0, 2, 4],\n    sensors=[radar2]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can pass the platforms into a detection simulator. At each timestep, the simulator will\nreturn the detections from the `sensor1_platform`, then the detections from the\n`sensor2_platform`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.simulator.platform import PlatformDetectionSimulator\nradar_simulator = PlatformDetectionSimulator(\n    groundtruth=gt_simulator,\n    platforms=[sensor1_platform, sensor2_platform]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's briefly visualize the truths and measurements before we move on. Note that the final\nsimulation will not have the same truths because the ground truth generator is randomized. But\nthis gives an idea of what it will look like. The detections from the first sensor (airborne)\nwill be plotted in blue, and the detections from the second sensor are in red. The clutter from\nboth sensors are plotted in yellow. The sensor locations will be plotted in green Xs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.plotter import Plotter, Dimension\n\n# Lists to hold the detections from each sensor and the path of the airborne radar\ns1_detections = []\ns2_detections = []\nradar1_path = []\n\n# Extract the generator function from a copy of the simulator\nsim = deepcopy(radar_simulator)\ng = sim.detections_gen()\n\n# Iterate over the time steps, extracting the detections, truths, and airborne sensor path\nfor _ in range(num_steps):\n    s1_detections.append(next(g)[1])\n    s2_detections.append(next(g)[1])\n    radar1_path.append(sim.platforms[0].position)\ntruths = set(sim.groundtruth.groundtruth_paths)\n\n# Plot the truths and detections\nplotter = Plotter(dimension=Dimension.THREE)\nplotter.plot_ground_truths(truths, [0, 2, 4])\nplotter.plot_measurements(s1_detections, [0, 2, 4], color='blue')\nplotter.plot_measurements(s2_detections, [0, 2, 4], color='red')\n\n# Plot the radar positions\nplotter.ax.plot(*zip(*radar1_path), marker='x', color='green')\nplotter.ax.plot(2000, 50, 0, marker='x', color='green')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3: Make Trackers for the Radars\nThe airborne radar will be tracking using a JPDA tracker, and the stationary one will use a\nGM-LCC. These trackers will not be given the platform detection simulation objects as parameters,\nwe will feed the measurements later to ensure that that the same measurements are used in the\nfusion trackers.\nTo start, we can calculate the clutter spatial density.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "clutter_area = np.prod(np.diff(clutter_model.dist_params))\nclutter_spatial_density = clutter_model.clutter_rate/clutter_area"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### JPDA Tracker\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.hypothesiser.probability import PDAHypothesiser\nfrom smartfusion.updater.kalman import ExtendedKalmanUpdater\nfrom smartfusion.predictor.kalman import ExtendedKalmanPredictor\nfrom smartfusion.dataassociator.probability import JPDA\nfrom smartfusion.deleter.error import CovarianceBasedDeleter\nfrom smartfusion.initiator.simple import MultiMeasurementInitiator\nfrom smartfusion.tracker.simple import MultiTargetMixtureTracker\n\n# Updater\njpda_updater = ExtendedKalmanUpdater(measurement_model=None)\n\n# Data Associator\npredictor = ExtendedKalmanPredictor(truth_transition_model)\nhypothesiser = PDAHypothesiser(\n    predictor=predictor,\n    updater=jpda_updater,\n    clutter_spatial_density=clutter_spatial_density,\n    prob_detect=0.9\n)\ndata_associator = JPDA(hypothesiser=hypothesiser)\n\n# Deleter\ncovariance_limit_for_delete = 500\ndeleter = CovarianceBasedDeleter(covar_trace_thresh=covariance_limit_for_delete)\n\n# Initiator\ns_prior_state = GaussianState([0, 0, 0, 0, 500, 0], np.diag([0, 50, 0, 50, 0, 50]))\nfrom smartfusion.hypothesiser.distance import DistanceHypothesiser\nfrom smartfusion.measures import Mahalanobis\nhypothesiser = DistanceHypothesiser(\n    predictor,\n    jpda_updater,\n    measure=Mahalanobis(),\n    missed_distance=3\n)\n\nfrom smartfusion.dataassociator.neighbour import GNNWith2DAssignment\ninitiator_associator = GNNWith2DAssignment(hypothesiser)\ninitiator_deleter = CovarianceBasedDeleter(covar_trace_thresh=500)\ninitiator = MultiMeasurementInitiator(\n    prior_state=s_prior_state,\n    measurement_model=None,\n    deleter=initiator_deleter,\n    data_associator=initiator_associator,\n    updater=jpda_updater,\n    min_points=2\n)\n\njpda_tracker = MultiTargetMixtureTracker(\n    initiator=initiator,\n    deleter=deleter,\n    detector=None,\n    data_associator=data_associator,\n    updater=jpda_updater\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GM-LCC Tracker\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.updater.pointprocess import LCCUpdater\nfrom smartfusion.hypothesiser.distance import DistanceHypothesiser\nfrom smartfusion.measures import Mahalanobis\nfrom smartfusion.hypothesiser.gaussianmixture import GaussianMixtureHypothesiser\nfrom smartfusion.mixturereducer.gaussianmixture import GaussianMixtureReducer\nfrom smartfusion.types.state import TaggedWeightedGaussianState\nfrom smartfusion.tracker.pointprocess import PointProcessMultiTargetTracker\n\n# Updater\nkalman_updater = ExtendedKalmanUpdater(measurement_model=None)\nupdater = LCCUpdater(\n    updater=kalman_updater,\n    clutter_spatial_density=clutter_spatial_density,\n    normalisation=True,\n    prob_detection=0.9,\n    prob_survival=0.9,\n    mean_number_of_false_alarms=clutter_model.clutter_rate,\n    variance_of_false_alarms=100\n)\n\n# Hypothesiser\nkalman_predictor = ExtendedKalmanPredictor(truth_transition_model)\nbase_hypothesiser = DistanceHypothesiser(\n    predictor=kalman_predictor,\n    updater=kalman_updater,\n    measure=Mahalanobis(),\n    missed_distance=15,\n    include_all=False\n)\nhypothesiser = GaussianMixtureHypothesiser(\n    base_hypothesiser,\n    order_by_detection=True\n)\n\n# Reducer\nreducer = GaussianMixtureReducer(\n    prune_threshold=1E-3,\n    pruning=True,\n    merge_threshold=200,\n    merging=True\n)\n\n# Birth component\nbirth_covar = CovarianceMatrix(np.diag([10000, 10, 10000, 10, 10000, 10]))\nbirth_component = TaggedWeightedGaussianState(\n    state_vector=[0, 0, 0, 0, 500, 0],\n    covar=birth_covar**2,\n    weight=0.5,\n    tag=TaggedWeightedGaussianState.BIRTH,\n    timestamp=start_time\n)\n\n# Tracker\ngmlcc_tracker = PointProcessMultiTargetTracker(\n    detector=None,\n    hypothesiser=deepcopy(hypothesiser),\n    updater=deepcopy(updater),\n    reducer=deepcopy(reducer),\n    birth_component=deepcopy(birth_component),\n    extraction_threshold=0.90,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4: Make GM-PHD Tracker For Measurement Fusion\nThis tracker can use many of the same elements as the GM-LCC one.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.updater.pointprocess import PHDUpdater\n\nupdater = PHDUpdater(\n    kalman_updater,\n    clutter_spatial_density=clutter_spatial_density,\n    prob_detection=0.9,\n    prob_survival=0.9\n)\n\nmeas_fusion_tracker = PointProcessMultiTargetTracker(\n    detector=None,\n    hypothesiser=deepcopy(hypothesiser),\n    updater=deepcopy(updater),\n    reducer=deepcopy(reducer),\n    birth_component=deepcopy(birth_component),\n    extraction_threshold=0.90,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5: Define a GM-PHD Tracker for Track Fusion\nTrack fusion using covariance intersection is implemented in SMART FUSION using the\n:class:`ChernoffUpdater` class. For use in a GM-PHD, we insert the :class:`ChernoffUpdater` as\nthe base updater, instead of a typical :class:`~.KalmanUpdater`. The `clutter_spatial_density`\nparameter now refers to the estimated intensity of false tracks. Since the previous tracker will\n(hopefully) have ignored some of the clutter, we can use a smaller intensity than in the previous\ntrackers. The `omega` parameter is also adjustable. We will set it to 0.5 for now.\n\nThe remaining tracker parameters have been kept the same as the measurement fusion tracker except\nwhere noted. This will ensure a fair comparison of the results.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.updater.chernoff import ChernoffUpdater\nfrom smartfusion.measures import Euclidean\n\n# Updater\nch_updater = ChernoffUpdater(measurement_model=None)\nupdater = PHDUpdater(\n    ch_updater,\n    clutter_spatial_density=1E-15,\n    prob_detection=0.9,\n    prob_survival=0.9\n)\n\n\n# Hypothesiser\n# The states being used as measurements are in Cartesian space. We will use Euclidean distance in\n# the :class:`~.DistanceHypothesiser`, meaning that we need a bigger missed distance than the\n# previous hypothesiser which used the Mahalanobis distance.\nkalman_predictor = ExtendedKalmanPredictor(truth_transition_model)\nbase_hypothesiser = DistanceHypothesiser(\n    kalman_predictor,\n    ch_updater,\n    Euclidean(),\n    missed_distance=300,\n    include_all=False\n)\nhypothesiser = GaussianMixtureHypothesiser(base_hypothesiser, order_by_detection=True)\n\n# Reducer\n# The states tend to have low weights when they are first initialized using this method, so we will\n# keep the pruning threshold low.\nch_reducer = GaussianMixtureReducer(\n    prune_threshold=1E-10,\n    pruning=True,\n    merge_threshold=200,\n    merging=True\n)\n\n# Birth component\nbirth_covar = CovarianceMatrix(np.diag([100000, 100, 100000, 100, 100000, 100]))\nch_birth_component = TaggedWeightedGaussianState(\n    state_vector=[0, 0, 0, 0, 500, 0],\n    covar=birth_covar**2,\n    weight=0.5,\n    tag=TaggedWeightedGaussianState.BIRTH,\n    timestamp=start_time\n)\n\n# Make tracker\ntrack_fusion_tracker = PointProcessMultiTargetTracker(\n    detector=None,\n    hypothesiser=hypothesiser,\n    updater=updater,\n    reducer=deepcopy(ch_reducer),\n    birth_component=deepcopy(ch_birth_component),\n    extraction_threshold=0.90,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6: Make Metric Managers\nWe will track the metrics of each of the four trackers for comparison.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.metricgenerator.basicmetrics import BasicMetrics\nfrom smartfusion.metricgenerator.ospametric import OSPAMetric\nfrom smartfusion.metricgenerator.tracktotruthmetrics import SIAPMetrics\nfrom smartfusion.metricgenerator.uncertaintymetric import SumofCovarianceNormsMetric\nfrom smartfusion.dataassociator.tracktotrack import TrackToTruth\nfrom smartfusion.metricgenerator.manager import SimpleManager\n\n# Make the basic metric manager\nbasic_generator = BasicMetrics()\nospa_generator = OSPAMetric(c=10, p=1, measure=Euclidean([0, 2, 4]))\nsiap_generator = SIAPMetrics(position_measure=Euclidean(), velocity_measure=Euclidean())\nuncertainty_generator = SumofCovarianceNormsMetric()\n\nassociator = TrackToTruth(association_threshold=30)\nbase_metric_manager = SimpleManager([basic_generator, ospa_generator, siap_generator,\n                                     uncertainty_generator],\n                                    associator=associator)\n\nsensor1_mm, sensor2_mm = deepcopy(base_metric_manager), deepcopy(base_metric_manager)\nmeas_fusion_mm, track_fusion_mm = deepcopy(base_metric_manager), deepcopy(base_metric_manager)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7: Set Up the Detection Feeders\nAs one final step before running the simulation, we will write a little class which feeds the\ndetections for a single timestep. This makes sure that the two radars and the measurement\nfusion tracker are getting the same measurements.\n\nThe track fusion tracker will also use the :class:`~.Tracks2GaussianDetectionFeeder` class to\nfeed the tracks as measurements. At each time step, the resultant live tracks from the JPDA and\nGM-LCC trackers will be put into a :class:`~.Tracks2GaussianDetectionFeeder` (using the\n:class:`~.DummyDetector` we write below). The feeder will take the most recent state from each\ntrack and turn it into a :class:`~.GaussianDetection` object. The set of detection objects will\nbe returned and passed into the tracker.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smartfusion.feeder.track import Tracks2GaussianDetectionFeeder\nfrom smartfusion.buffered_generator import BufferedGenerator\nfrom smartfusion.reader.base import DetectionReader\n\n\nclass DummyDetector(DetectionReader):\n    def __init__(self, *args, **kwargs):\n        self.current = kwargs['current']\n\n    @BufferedGenerator.generator_method\n    def detections_gen(self):\n        yield self.current"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8: Run Simulation\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sensor1_detections, sensor2_detections = [], []\njpda_tracks, gmlcc_tracks = set(), set()\nmeas_fusion_tracks, track_fusion_tracks = set(), set()\n\nsim_generator = radar_simulator.detections_gen()\n\nfor t in range(num_steps):\n\n    # Run JPDA tracker from sensor 1\n    s1d = next(sim_generator)\n    sensor1_detections.extend(s1d[1])  # hold in list for plotting\n    # Pass the detections into a DummyDetector and set it up as an iterable\n    jpda_tracker.detector = DummyDetector(current=s1d)\n    jpda_tracker.__iter__()\n    # Run the tracker and store the resulting tracks\n    _, sensor1_tracks = next(jpda_tracker)\n    jpda_tracks.update(sensor1_tracks)\n\n    # Run GM-LCC tracker from sensor 2\n    s2d = next(sim_generator)\n    sensor2_detections.extend(s2d[1])  # hold in list for plotting\n    # Pass the detections into a DummyDetector and set it up as an iterable\n    gmlcc_tracker.detector = DummyDetector(current=s2d)\n    gmlcc_tracker.__iter__()\n    # Run the tracker and store results\n    time, sensor2_tracks = next(gmlcc_tracker)\n    gmlcc_tracks.update(sensor2_tracks)\n\n    # Run the GM-PHD for measurement fusion. This one gets called twice, once for each set of\n    # detections. This ensures there is only one detection per target.\n    for detections in [s1d, s2d]:\n        meas_fusion_tracker.detector = DummyDetector(current=detections)\n        meas_fusion_tracker.__iter__()\n        _, tracks = next(meas_fusion_tracker)\n        meas_fusion_tracks.update(tracks)\n\n    # Run the GM-PHD for track fusion. Similar to the measurement fusion, this tracker gets run\n    # twice, once for each set of tracks.\n    for tracks_as_meas in [sensor1_tracks, sensor2_tracks]:\n        dummy_detector = DummyDetector(current=[time, tracks_as_meas])\n        track_fusion_tracker.detector = Tracks2GaussianDetectionFeeder(dummy_detector)\n        track_fusion_tracker.__iter__()\n        _, tracks = next(track_fusion_tracker)\n        track_fusion_tracks.update(tracks)\n\n    # ----------------------------------------------------------------------\n\n    # Add ground truth data to metric managers\n    truths = radar_simulator.groundtruth.current\n    for manager in [sensor1_mm, sensor2_mm, meas_fusion_mm, track_fusion_mm]:\n        manager.add_data(groundtruth_paths=truths[1], overwrite=False)\n\n    # Add measurements to metric managers\n    sensor1_mm.add_data(detections=s1d[1], overwrite=False)\n    sensor2_mm.add_data(detections=s2d[1], overwrite=False)\n    meas_fusion_mm.add_data(detections=s1d[1], overwrite=False)\n    meas_fusion_mm.add_data(detections=s2d[1], overwrite=False)\n    track_fusion_mm.add_data(detections=s1d[1], overwrite=False)\n    track_fusion_mm.add_data(detections=s2d[1], overwrite=False)\n\n\n# Ensure that all tracks have been extracted from the trackers\njpda_tracks.update(jpda_tracker.tracks)\ngmlcc_tracks.update(gmlcc_tracker.tracks)\nmeas_fusion_tracks.update(meas_fusion_tracker.tracks)\ntrack_fusion_tracks.update(track_fusion_tracker.tracks)\n\n# Remove tracks that have just one state in them as they were probably from clutter\njpda_tracks = set([track for track in jpda_tracks if len(track) > 1])\ngmlcc_tracks = set([track for track in gmlcc_tracks if len(track) > 1])\nmeas_fusion_tracks = set([track for track in meas_fusion_tracks if len(track) > 1])\ntrack_fusion_tracks = set([track for track in track_fusion_tracks if len(track) > 1])\n\n# Add tracks to metric managers\nsensor1_mm.add_data(tracks=jpda_tracks, overwrite=False)\nsensor2_mm.add_data(tracks=gmlcc_tracks, overwrite=False)\nmeas_fusion_mm.add_data(tracks=meas_fusion_tracks, overwrite=False)\ntrack_fusion_mm.add_data(tracks=track_fusion_tracks, overwrite=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9: Plot the Results\nNext, we will plot all of the resulting tracks and measurements. This will be done in two plots.\nThe first plot will show all of the data, and the second plot will show a closer view of one\nresultant track.\n\nThese plots are done in 2D to make them more readable. We invite the reader to explore the plot\ninteractively using the following line in an active Jupyter session.\n\n%matplotlib widget\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plotter1, plotter2 = Plotter(), Plotter()\nfor plotter in [plotter1, plotter2]:\n    plotter.plot_ground_truths(set(radar_simulator.groundtruth.groundtruth_paths), [0, 2],\n                               color='black')\n    plotter.plot_measurements(sensor1_detections, [0, 2], color='orange', marker='*',\n                              measurements_label='Measurements - Airborne Radar')\n    plotter.plot_measurements(sensor2_detections, [0, 2], color='blue', marker='*',\n                              measurements_label='Measurements - Ground Radar')\n    plotter.plot_tracks(jpda_tracks, [0, 2], color='red',\n                        track_label='Tracks - Airborne Radar (JPDAF)')\n    plotter.plot_tracks(gmlcc_tracks, [0, 2], color='purple',\n                        track_label='Tracks - Ground Radar (GM-LCC)')\n    plotter.plot_tracks(meas_fusion_tracks, [0, 2], color='green',\n                        track_label='Tracks - Measurement Fusion (GM-PHD)')\n    plotter.plot_tracks(track_fusion_tracks, [0, 2], color='pink',\n                        track_label='Tracks - Covariance Intersection (GM-PHD)')\n\n    # Format the legend a bit. Set the position outside of the plot, and\n    # swap the order of the clutter and ground radar measurements\n    pos = plotter.ax.get_position()\n    plotter.ax.set_position([pos.x0, pos.y0, pos.width * 0.7, pos.height])\n    k = list(plotter.legend_dict.keys())\n    k[2], k[3] = k[3], k[2]\n    v = list(plotter.legend_dict.values())\n    v[2], v[3] = v[3], v[2]\n    plotter.ax.legend(handles=v, labels=k, loc='lower center', bbox_to_anchor=(0.5, -0.5))\n\nplotter1.fig.show()\n\ntrack = track_fusion_tracks.pop()\nx_min = min([state.state_vector[0] for state in track])\nx_max = max([state.state_vector[0] for state in track])\ny_min = min([state.state_vector[2] for state in track])\ny_max = max([state.state_vector[2] for state in track])\n\nplotter2.ax.set_xlim(x_min-50, x_max+50)\nplotter2.ax.set_ylim(y_min-50, y_max+50)\n\nplotter2.fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we will plot the metrics. First, we call a function for each sensor manager to calculate\nthe metrics.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "s1_metrics = sensor1_mm.generate_metrics()\ns2_metrics = sensor2_mm.generate_metrics()\nmeas_fusion_metrics = meas_fusion_mm.generate_metrics()\ntrack_fusion_metrics = track_fusion_mm.generate_metrics()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can plot them. The SIAP and OSPA metrics can be done together in a loop. The\nTrack-To-Truth ratio needs to be done separately so that it can be calculated at each\ntimestep.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\nfrom smartfusion.metricgenerator.tracktotruthmetrics import SIAPMetrics\n\n# Legend labels for each type of tracker\nlabels = ['Airborne Radar (JPDAF)', 'Ground Radar (GM-LCC)', 'Measurement Fusion (GM-PHD)',\n          'Covariance Intersection (GM-PHD)']\nlinestyles = ['dashed', 'dotted', 'solid', 'dashdot']\n\n# Iterate through the SIAP and OSPA metrics\nfor metric_name in ['SIAP Position Accuracy at times', 'SIAP Velocity Accuracy at times',\n                    'SIAP Spuriousness at times', 'SIAP Completeness at times',\n                    'SIAP Ambiguity at times', 'OSPA distances', 'Sum of Covariance Norms Metric']:\n    fig, ax = plt.subplots()\n\n    # Plot the metrics from each metric manager\n    for tracker_metrics, label, line in zip([s1_metrics, s2_metrics, meas_fusion_metrics,\n                                             track_fusion_metrics], labels, linestyles):\n        metrics = tracker_metrics[metric_name]\n        ax.plot([m.value for m in metrics.value], linewidth=2, label=label, linestyle=line)\n\n    # Set x and y labels and title\n    ax.set_xlabel(\"Time $(s)$\")\n    if metric_name.startswith('OSPA'):\n        ax.set_title('OSPA Distance')\n        ax.set_ylabel('Distance')\n        ax.set_ylim(0, 12)  # change y axis range for OSPA distance\n    elif metric_name.startswith('Sum of'):\n        ax.set_title(metric_name)\n        ax.set_ylabel('Sum of Covariance Norms')\n    else:\n        ax.set_title(metric_name)\n        ax.set_ylabel(metric_name[5:-9])\n\n    # Add units to y axis where applicable\n    if metric_name.startswith('SIAP Position') or metric_name.startswith('SIAP Velocity') \\\n       or metric_name.startswith('OSPA'):\n        ax.set_ylabel(ax.yaxis.get_label().get_text() + ' $(m)$')\n\n    # Add legend\n    ax.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n\n\n# Plot Track to Truth Ratio\nfig, ax = plt.subplots()\ntimes = sensor1_mm.list_timestamps()\n\n# Iterate through the metric managers. For each one, go through the list of all timesteps\n# and calculate the ratio at that time\nfor manager, label, line in zip([sensor1_mm, sensor2_mm, meas_fusion_mm, track_fusion_mm],\n                                labels, linestyles):\n    ratios = []\n    for time in times:\n        num_tracks = SIAPMetrics.num_tracks_at_time(manager=manager, timestamp=time)\n        num_truths = SIAPMetrics.num_truths_at_time(manager=manager, timestamp=time)\n        ratios.append(num_tracks / num_truths)\n    plt.plot(ratios, linewidth=2, label=label, linestyle=line)\n\nax.set_title('Track-to-Truth Ratio')\nax.set_ylabel('Ratio')\nax.set_xlabel('Time $(s)$')\nax.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n.. [#] Julier, S. J. and Uhlmann, J. K., \u201cGeneral decentralized data fusion\n        with covariance intersection,\u201d Handbook of multisensor data fusion:\n        theory and practice, pp. 319\u2013344, 2009.\n\n.. [#] Clark, D. E. and Campbell, M. A., \u201cIntegrating covariance intersection\n       into Bayesian multi-target tracking filters,\u201d preprint on TechRxiv.\n       submitted to IEEE Transactions on Aerospace and Electronic Systems.\n\n.. [#] Hurley, M. B., \u201cAn information theoretic justification for covariance\n       intersection and its generalization,\u201d in Proceedings of the Fifth\n       International Conference on Information Fusion. FUSION 2002.(IEEE Cat.\n       No. 02EX5997), vol. 1. IEEE, 2002, pp. 505\u2013511\n\n.. [#] Clark, D. and Hunter, E. and Balaji, B. and O'Rourke, S., \u201cCentralized multi-sensor\n       multi-target data fusion with tracks as measurements,\u201d to be submitted to SPIE Defense and\n       Security Symposium 2023.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}